{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRQaYx9PYpOm"
      },
      "source": [
        "## Configuração de Ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from config import result_index\n",
        "\n",
        "results_folder = f\"results_{result_index}\"\n",
        "results_file = f\"{results_folder}/finetuning_results.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCwYm-vtYpOq",
        "outputId": "ff0187e4-afbf-4a23-fcf3-2bf9ddd3f6f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.10.3)\n",
            "Requirement already satisfied: bertopic in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.17.0)\n",
            "Requirement already satisfied: plotly in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (6.1.2)\n",
            "Requirement already satisfied: datamapplot in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.6.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: hdbscan>=0.8.29 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bertopic) (0.8.40)\n",
            "Requirement already satisfied: pandas>=1.1.5 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bertopic) (2.2.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bertopic) (1.6.1)\n",
            "Requirement already satisfied: sentence-transformers>=0.4.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bertopic) (4.1.0)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bertopic) (4.67.1)\n",
            "Requirement already satisfied: umap-learn>=0.5.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bertopic) (0.5.7)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from plotly) (1.42.1)\n",
            "Requirement already satisfied: colorcet in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (3.1.0)\n",
            "Requirement already satisfied: colorspacious>=1.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (1.1.2)\n",
            "Requirement already satisfied: dask<2025.0.1,>=2024.4.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (2024.12.1)\n",
            "Requirement already satisfied: datashader>=0.16 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (6.5.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (3.1.6)\n",
            "Requirement already satisfied: numba>=0.56 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (0.61.2)\n",
            "Requirement already satisfied: pyarrow in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (20.0.0)\n",
            "Requirement already satisfied: pylabeladjust in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (0.1.13)\n",
            "Requirement already satisfied: requests in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (2.32.3)\n",
            "Requirement already satisfied: rcssmin>=1.1.2 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (1.2.1)\n",
            "Requirement already satisfied: rjsmin>=1.2.2 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (1.2.4)\n",
            "Requirement already satisfied: scikit-image>=0.22 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (0.25.2)\n",
            "Requirement already satisfied: platformdirs in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (4.3.7)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (4.13.2)\n",
            "Requirement already satisfied: click>=8.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (3.1.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (2024.12.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (1.0.0)\n",
            "Requirement already satisfied: importlib_metadata>=4.13.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (8.7.0)\n",
            "Requirement already satisfied: lz4>=4.3.2 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (4.4.4)\n",
            "Requirement already satisfied: multipledispatch in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datashader>=0.16->datamapplot) (1.0.0)\n",
            "Requirement already satisfied: param in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datashader>=0.16->datamapplot) (2.2.1)\n",
            "Requirement already satisfied: pyct in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datashader>=0.16->datamapplot) (0.5.0)\n",
            "Requirement already satisfied: scipy in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datashader>=0.16->datamapplot) (1.13.1)\n",
            "Requirement already satisfied: xarray in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datashader>=0.16->datamapplot) (2025.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from hdbscan>=0.8.29->bertopic) (1.4.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from numba>=0.56->datamapplot) (0.44.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.1.5->bertopic) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.1.5->bertopic) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: networkx>=3.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-image>=0.22->datamapplot) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-image>=0.22->datamapplot) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-image>=0.22->datamapplot) (2025.6.11)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-image>=0.22->datamapplot) (0.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn>=1.0->bertopic) (3.6.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers>=0.4.1->bertopic) (4.51.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers>=0.4.1->bertopic) (2.7.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers>=0.4.1->bertopic) (0.30.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.41.1->bertopic) (0.4.6)\n",
            "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from umap-learn>=0.5.0->bertopic) (0.5.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->datamapplot) (3.0.2)\n",
            "Requirement already satisfied: Pyqtree<2.0.0,>=1.0.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pylabeladjust->datamapplot) (1.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->datamapplot) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->datamapplot) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->datamapplot) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->datamapplot) (2025.4.26)\n",
            "Requirement already satisfied: filelock in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.18.0)\n",
            "Requirement already satisfied: zipp>=3.20 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from importlib_metadata>=4.13.0->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (3.21.0)\n",
            "Requirement already satisfied: locket in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from partd>=1.4.0->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (1.0.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.14.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.5.3)\n",
            "Requirement already satisfied: dask-expr<1.2,>=1.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (1.1.21)\n",
            "Requirement already satisfied: distributed==2024.12.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (2024.12.1)\n",
            "Requirement already satisfied: bokeh>=3.1.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (3.7.3)\n",
            "Requirement already satisfied: msgpack>=1.0.2 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from distributed==2024.12.1->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (1.1.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from distributed==2024.12.1->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (7.0.0)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from distributed==2024.12.1->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from distributed==2024.12.1->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (3.1.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from distributed==2024.12.1->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (6.4.2)\n",
            "Requirement already satisfied: zict>=3.0.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from distributed==2024.12.1->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (3.0.0)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bokeh>=3.1.0->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (2025.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
            "[notice] To update, run: C:\\Users\\vmart\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.84.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (2.11.3)\n",
            "Requirement already satisfied: sniffio in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
            "[notice] To update, run: C:\\Users\\vmart\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.51.3)\n",
            "Requirement already satisfied: sympy in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.14.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy) (1.3.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2025.4.26)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
            "[notice] To update, run: C:\\Users\\vmart\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wordcloud in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.9.4)\n",
            "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from wordcloud) (1.26.4)\n",
            "Requirement already satisfied: pillow in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from wordcloud) (11.2.1)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from wordcloud) (3.10.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
            "[notice] To update, run: C:\\Users\\vmart\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Usage:   \n",
            "  C:\\Users\\vmart\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install [options] <requirement specifier> [package-index-options] ...\n",
            "  C:\\Users\\vmart\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install [options] -r <requirements file> [package-index-options] ...\n",
            "  C:\\Users\\vmart\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install [options] [-e] <vcs project url> ...\n",
            "  C:\\Users\\vmart\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install [options] [-e] <local project path> ...\n",
            "  C:\\Users\\vmart\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -u\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.24.4\n",
            "  Downloading numpy-1.24.4-cp311-cp311-win_amd64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: gensim in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.3.3)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading numpy-1.24.4-cp311-cp311-win_amd64.whl (14.8 MB)\n",
            "   ---------------------------------------- 0.0/14.8 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/14.8 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/14.8 MB 653.6 kB/s eta 0:00:23\n",
            "    --------------------------------------- 0.3/14.8 MB 2.8 MB/s eta 0:00:06\n",
            "   ----- ---------------------------------- 2.0/14.8 MB 14.4 MB/s eta 0:00:01\n",
            "   ----------- ---------------------------- 4.3/14.8 MB 23.2 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 6.3/14.8 MB 27.1 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 7.9/14.8 MB 29.6 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 10.2/14.8 MB 32.8 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 13.0/14.8 MB 50.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  14.8/14.8 MB 46.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 14.8/14.8 MB 40.9 MB/s eta 0:00:00\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "Successfully installed numpy-1.24.4\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\vmart\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\~-mpy.libs'.\n",
            "  You can safely remove it manually.\n",
            "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\vmart\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\~-mpy'.\n",
            "  You can safely remove it manually.\n",
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
            "[notice] To update, run: C:\\Users\\vmart\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade matplotlib bertopic plotly datamapplot\n",
        "%pip install openai\n",
        "%pip install transformers sympy\n",
        "%pip install wordcloud\n",
        "%pip install -u kaleido\n",
        "%pip install numpy==1.24.4 gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ecvfqx4D3NNc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\vmart\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from gensim.corpora import Dictionary\n",
        "\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "import logging\n",
        "from itertools import product\n",
        "\n",
        "from bertopic import BERTopic\n",
        "from bertopic.representation import MaximalMarginalRelevance, KeyBERTInspired, OpenAI\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
        "\n",
        "from hdbscan import HDBSCAN\n",
        "import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKMwXSj4YpOu"
      },
      "source": [
        "## Importação de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AJSGkZCOZKcy"
      },
      "outputs": [],
      "source": [
        "# Substitua pelo caminho correto\n",
        "file_path = f'processed_data_{result_index}/cleaned_videos.csv'\n",
        "\n",
        "df = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>video_id</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>channel_id</th>\n",
              "      <th>published_at</th>\n",
              "      <th>category_id</th>\n",
              "      <th>tags</th>\n",
              "      <th>view_count</th>\n",
              "      <th>...</th>\n",
              "      <th>concurrent_viewers</th>\n",
              "      <th>active_live_chat_id</th>\n",
              "      <th>recording_date</th>\n",
              "      <th>topicCategories</th>\n",
              "      <th>processing_status</th>\n",
              "      <th>parts_total</th>\n",
              "      <th>parts_processed</th>\n",
              "      <th>time_left_ms</th>\n",
              "      <th>processing_failure_reason</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>264</td>\n",
              "      <td>294.0</td>\n",
              "      <td>nO06xfLips8</td>\n",
              "      <td>Mãe sensata? É ótimo! Mas homem que só amadure...</td>\n",
              "      <td>#rafaelaires #antiotario #redpillbrasil\\n\\n🔥 P...</td>\n",
              "      <td>UCAYoI16-UkXemcnhC-kTvDQ</td>\n",
              "      <td>2025-05-12 21:00:54</td>\n",
              "      <td>22</td>\n",
              "      <td>[]</td>\n",
              "      <td>113</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://en.wikipedia.org/wiki/Society']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>mãe sensata é ótimo ma homem que só amadurece ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>832</td>\n",
              "      <td>NaN</td>\n",
              "      <td>wUQwbUKrzME</td>\n",
              "      <td>Não seja o cara que implora! Mulher admira cor...</td>\n",
              "      <td>#rafaelaires #antiotario #redpillbrasil\\n\\n🔥 P...</td>\n",
              "      <td>UCAYoI16-UkXemcnhC-kTvDQ</td>\n",
              "      <td>2025-05-06 21:01:05</td>\n",
              "      <td>22</td>\n",
              "      <td>[]</td>\n",
              "      <td>129</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://en.wikipedia.org/wiki/Lifestyle_(soc...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>não seja cara que implora mulher admira corage...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>228</td>\n",
              "      <td>255.0</td>\n",
              "      <td>w7tH6YIZyqc</td>\n",
              "      <td>MULHER DIZ QUE PAGA MARIDO PARA TER RELAÇÃO CO...</td>\n",
              "      <td>Olá! seja bem vindo a mais um video do canal, ...</td>\n",
              "      <td>UCRmNflJuD1TxLbRlDV08_7g</td>\n",
              "      <td>2025-05-15 01:55:09</td>\n",
              "      <td>24</td>\n",
              "      <td>['red pill', 'divorcio', 'pensão socio afetiva...</td>\n",
              "      <td>2718</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://en.wikipedia.org/wiki/Humour', 'http...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>mulher diz que paga marido para ter relação co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>21.0</td>\n",
              "      <td>2YhQqPj6aSQ</td>\n",
              "      <td>Homem feio tem mais chance de ser fiel? | Qual...</td>\n",
              "      <td>#rafaelaires #antiotario #redpillbrasil\\n\\n🔥 P...</td>\n",
              "      <td>UCAYoI16-UkXemcnhC-kTvDQ</td>\n",
              "      <td>2025-05-29 21:00:02</td>\n",
              "      <td>22</td>\n",
              "      <td>[]</td>\n",
              "      <td>708951</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>homem feio tem mais chance de ser fiel qual su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>794</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fdz39IZljTg</td>\n",
              "      <td>COROA CONTA QUE CONHECEU UM NOVINHO NUMA REDE ...</td>\n",
              "      <td>seja bem vindo a mais um vídeo do canal Não se...</td>\n",
              "      <td>UCUBeVY6Kn7ulBmUGynJqISw</td>\n",
              "      <td>2025-05-09 02:19:06</td>\n",
              "      <td>24</td>\n",
              "      <td>['redpill', 'msol', 'miqueinha', 'relacionamen...</td>\n",
              "      <td>1148</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://en.wikipedia.org/wiki/Humour', 'http...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>coroa conta que conheceu um novinho numa rede ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 38 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0.1  Unnamed: 0     video_id  \\\n",
              "264           264       294.0  nO06xfLips8   \n",
              "349           832         NaN  wUQwbUKrzME   \n",
              "228           228       255.0  w7tH6YIZyqc   \n",
              "20             20        21.0  2YhQqPj6aSQ   \n",
              "314           794         NaN  Fdz39IZljTg   \n",
              "\n",
              "                                                 title  \\\n",
              "264  Mãe sensata? É ótimo! Mas homem que só amadure...   \n",
              "349  Não seja o cara que implora! Mulher admira cor...   \n",
              "228  MULHER DIZ QUE PAGA MARIDO PARA TER RELAÇÃO CO...   \n",
              "20   Homem feio tem mais chance de ser fiel? | Qual...   \n",
              "314  COROA CONTA QUE CONHECEU UM NOVINHO NUMA REDE ...   \n",
              "\n",
              "                                           description  \\\n",
              "264  #rafaelaires #antiotario #redpillbrasil\\n\\n🔥 P...   \n",
              "349  #rafaelaires #antiotario #redpillbrasil\\n\\n🔥 P...   \n",
              "228  Olá! seja bem vindo a mais um video do canal, ...   \n",
              "20   #rafaelaires #antiotario #redpillbrasil\\n\\n🔥 P...   \n",
              "314  seja bem vindo a mais um vídeo do canal Não se...   \n",
              "\n",
              "                   channel_id         published_at  category_id  \\\n",
              "264  UCAYoI16-UkXemcnhC-kTvDQ  2025-05-12 21:00:54           22   \n",
              "349  UCAYoI16-UkXemcnhC-kTvDQ  2025-05-06 21:01:05           22   \n",
              "228  UCRmNflJuD1TxLbRlDV08_7g  2025-05-15 01:55:09           24   \n",
              "20   UCAYoI16-UkXemcnhC-kTvDQ  2025-05-29 21:00:02           22   \n",
              "314  UCUBeVY6Kn7ulBmUGynJqISw  2025-05-09 02:19:06           24   \n",
              "\n",
              "                                                  tags  view_count  ...  \\\n",
              "264                                                 []         113  ...   \n",
              "349                                                 []         129  ...   \n",
              "228  ['red pill', 'divorcio', 'pensão socio afetiva...        2718  ...   \n",
              "20                                                  []      708951  ...   \n",
              "314  ['redpill', 'msol', 'miqueinha', 'relacionamen...        1148  ...   \n",
              "\n",
              "     concurrent_viewers  active_live_chat_id recording_date  \\\n",
              "264                   0                  NaN            NaN   \n",
              "349                   0                  NaN            NaN   \n",
              "228                   0                  NaN            NaN   \n",
              "20                    0                  NaN            NaN   \n",
              "314                   0                  NaN            NaN   \n",
              "\n",
              "                                       topicCategories  processing_status  \\\n",
              "264          ['https://en.wikipedia.org/wiki/Society']                NaN   \n",
              "349  ['https://en.wikipedia.org/wiki/Lifestyle_(soc...                NaN   \n",
              "228  ['https://en.wikipedia.org/wiki/Humour', 'http...                NaN   \n",
              "20                                                  []                NaN   \n",
              "314  ['https://en.wikipedia.org/wiki/Humour', 'http...                NaN   \n",
              "\n",
              "     parts_total parts_processed time_left_ms  processing_failure_reason  \\\n",
              "264            0               0            0                        NaN   \n",
              "349            0               0            0                        NaN   \n",
              "228            0               0            0                        NaN   \n",
              "20             0               0            0                        NaN   \n",
              "314            0               0            0                        NaN   \n",
              "\n",
              "                                                  text  \n",
              "264  mãe sensata é ótimo ma homem que só amadurece ...  \n",
              "349  não seja cara que implora mulher admira corage...  \n",
              "228  mulher diz que paga marido para ter relação co...  \n",
              "20   homem feio tem mais chance de ser fiel qual su...  \n",
              "314  coroa conta que conheceu um novinho numa rede ...  \n",
              "\n",
              "[5 rows x 38 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "447  textos\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0.1', 'Unnamed: 0', 'video_id', 'title', 'description',\n",
              "       'channel_id', 'published_at', 'category_id', 'tags', 'view_count',\n",
              "       'like_count', 'comment_count', 'duration', 'definition', 'caption',\n",
              "       'licensed_content', 'privacy_status', 'license', 'embeddable',\n",
              "       'public_stats_viewable', 'is_made_for_kids', 'thumbnail_url',\n",
              "       'default_audio_language', 'default_language', 'actual_start_time',\n",
              "       'scheduled_start_time', 'actual_end_time', 'scheduled_end_time',\n",
              "       'concurrent_viewers', 'active_live_chat_id', 'recording_date',\n",
              "       'topicCategories', 'processing_status', 'parts_total',\n",
              "       'parts_processed', 'time_left_ms', 'processing_failure_reason', 'text'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(len(df), \" textos\")\n",
        "\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['UCO9FRrBUwGdYopkMbGGKbpg', 'UCAYoI16-UkXemcnhC-kTvDQ',\n",
              "       'UCRmNflJuD1TxLbRlDV08_7g', 'UCUBeVY6Kn7ulBmUGynJqISw',\n",
              "       'UCeL1a4rpEA8UG9IQIewPccg', 'UC3nQ4xUl6rodOWuQbBULyow',\n",
              "       'UCNiU1wZxK6YN-KuJP7QMpBQ', 'UCX0VSzJ2z5l0C9wnwh5SoRw',\n",
              "       'UCExFA9MsrRmWnXUlhiwu4qA'], dtype=object)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['channel_id'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_videos = df.sample(n=100, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = pd.concat([train_videos])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>video_id</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>channel_id</th>\n",
              "      <th>published_at</th>\n",
              "      <th>category_id</th>\n",
              "      <th>tags</th>\n",
              "      <th>view_count</th>\n",
              "      <th>...</th>\n",
              "      <th>concurrent_viewers</th>\n",
              "      <th>active_live_chat_id</th>\n",
              "      <th>recording_date</th>\n",
              "      <th>topicCategories</th>\n",
              "      <th>processing_status</th>\n",
              "      <th>parts_total</th>\n",
              "      <th>parts_processed</th>\n",
              "      <th>time_left_ms</th>\n",
              "      <th>processing_failure_reason</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>378</th>\n",
              "      <td>863</td>\n",
              "      <td>NaN</td>\n",
              "      <td>k_9RUZzvCwY</td>\n",
              "      <td>PRESAS DIZEM PARA AS NOVINHAS NÃO FAZER COISA ...</td>\n",
              "      <td>seja bem vindo a mais um vídeo do canal Não se...</td>\n",
              "      <td>UCUBeVY6Kn7ulBmUGynJqISw</td>\n",
              "      <td>2025-05-05 11:19:45</td>\n",
              "      <td>24</td>\n",
              "      <td>['redpill', 'msol', 'miqueinha', 'relacionamen...</td>\n",
              "      <td>682</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://en.wikipedia.org/wiki/Lifestyle_(soc...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>presas dizem para novinhas não fazer coisa err...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>75</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9U9Rq6_B5Ts</td>\n",
              "      <td>Sinais que ela vai te colocar na cadeia! | Qua...</td>\n",
              "      <td>#rafaelaires #antiotario #redpillbrasil\\n\\n🔥 P...</td>\n",
              "      <td>UCAYoI16-UkXemcnhC-kTvDQ</td>\n",
              "      <td>2025-05-26 15:00:25</td>\n",
              "      <td>22</td>\n",
              "      <td>[]</td>\n",
              "      <td>37994</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://en.wikipedia.org/wiki/Health']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>sinai que ela vai te colocar na cadeia qual su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>79</td>\n",
              "      <td>84.0</td>\n",
              "      <td>7qkwWygX8y8</td>\n",
              "      <td>A mulher que não é submissa ao marido está fad...</td>\n",
              "      <td>#rafaelaires #antiotario #redpillbrasil\\n\\n🔥 P...</td>\n",
              "      <td>UCAYoI16-UkXemcnhC-kTvDQ</td>\n",
              "      <td>2025-05-26 12:00:13</td>\n",
              "      <td>22</td>\n",
              "      <td>[]</td>\n",
              "      <td>75205</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>mulher que não é submissa ao marido está fadad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>537</td>\n",
              "      <td>NaN</td>\n",
              "      <td>lRscpUdKfVU</td>\n",
              "      <td>Rapaz leva flores e amiga da namorada debocha....</td>\n",
              "      <td>#rafaelaires #antiotario #redpillbrasil\\n\\n🔥 P...</td>\n",
              "      <td>UCAYoI16-UkXemcnhC-kTvDQ</td>\n",
              "      <td>2025-05-25 15:01:12</td>\n",
              "      <td>22</td>\n",
              "      <td>[]</td>\n",
              "      <td>8802</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://en.wikipedia.org/wiki/Society']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>rapaz lev flores e amiga da namorada debocha q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>517</td>\n",
              "      <td>NaN</td>\n",
              "      <td>GjYlzOd82Qc</td>\n",
              "      <td>MULHER GRAVANDO PARA PROVAR QUE NÃO PRECISA DE...</td>\n",
              "      <td>Olá! seja bem vindo a mais um video do canal, ...</td>\n",
              "      <td>UCRmNflJuD1TxLbRlDV08_7g</td>\n",
              "      <td>2025-05-27 02:01:00</td>\n",
              "      <td>24</td>\n",
              "      <td>['red pill', 'divorcio', 'pensão socio afetiva...</td>\n",
              "      <td>255</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://en.wikipedia.org/wiki/Entertainment'...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>mulher gravando para provar que não precisa de...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 38 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0.1  Unnamed: 0     video_id  \\\n",
              "378           863         NaN  k_9RUZzvCwY   \n",
              "75             75        80.0  9U9Rq6_B5Ts   \n",
              "79             79        84.0  7qkwWygX8y8   \n",
              "84            537         NaN  lRscpUdKfVU   \n",
              "66            517         NaN  GjYlzOd82Qc   \n",
              "\n",
              "                                                 title  \\\n",
              "378  PRESAS DIZEM PARA AS NOVINHAS NÃO FAZER COISA ...   \n",
              "75   Sinais que ela vai te colocar na cadeia! | Qua...   \n",
              "79   A mulher que não é submissa ao marido está fad...   \n",
              "84   Rapaz leva flores e amiga da namorada debocha....   \n",
              "66   MULHER GRAVANDO PARA PROVAR QUE NÃO PRECISA DE...   \n",
              "\n",
              "                                           description  \\\n",
              "378  seja bem vindo a mais um vídeo do canal Não se...   \n",
              "75   #rafaelaires #antiotario #redpillbrasil\\n\\n🔥 P...   \n",
              "79   #rafaelaires #antiotario #redpillbrasil\\n\\n🔥 P...   \n",
              "84   #rafaelaires #antiotario #redpillbrasil\\n\\n🔥 P...   \n",
              "66   Olá! seja bem vindo a mais um video do canal, ...   \n",
              "\n",
              "                   channel_id         published_at  category_id  \\\n",
              "378  UCUBeVY6Kn7ulBmUGynJqISw  2025-05-05 11:19:45           24   \n",
              "75   UCAYoI16-UkXemcnhC-kTvDQ  2025-05-26 15:00:25           22   \n",
              "79   UCAYoI16-UkXemcnhC-kTvDQ  2025-05-26 12:00:13           22   \n",
              "84   UCAYoI16-UkXemcnhC-kTvDQ  2025-05-25 15:01:12           22   \n",
              "66   UCRmNflJuD1TxLbRlDV08_7g  2025-05-27 02:01:00           24   \n",
              "\n",
              "                                                  tags  view_count  ...  \\\n",
              "378  ['redpill', 'msol', 'miqueinha', 'relacionamen...         682  ...   \n",
              "75                                                  []       37994  ...   \n",
              "79                                                  []       75205  ...   \n",
              "84                                                  []        8802  ...   \n",
              "66   ['red pill', 'divorcio', 'pensão socio afetiva...         255  ...   \n",
              "\n",
              "     concurrent_viewers  active_live_chat_id recording_date  \\\n",
              "378                   0                  NaN            NaN   \n",
              "75                    0                  NaN            NaN   \n",
              "79                    0                  NaN            NaN   \n",
              "84                    0                  NaN            NaN   \n",
              "66                    0                  NaN            NaN   \n",
              "\n",
              "                                       topicCategories  processing_status  \\\n",
              "378  ['https://en.wikipedia.org/wiki/Lifestyle_(soc...                NaN   \n",
              "75            ['https://en.wikipedia.org/wiki/Health']                NaN   \n",
              "79                                                  []                NaN   \n",
              "84           ['https://en.wikipedia.org/wiki/Society']                NaN   \n",
              "66   ['https://en.wikipedia.org/wiki/Entertainment'...                NaN   \n",
              "\n",
              "     parts_total parts_processed time_left_ms  processing_failure_reason  \\\n",
              "378            0               0            0                        NaN   \n",
              "75             0               0            0                        NaN   \n",
              "79             0               0            0                        NaN   \n",
              "84             0               0            0                        NaN   \n",
              "66             0               0            0                        NaN   \n",
              "\n",
              "                                                  text  \n",
              "378  presas dizem para novinhas não fazer coisa err...  \n",
              "75   sinai que ela vai te colocar na cadeia qual su...  \n",
              "79   mulher que não é submissa ao marido está fadad...  \n",
              "84   rapaz lev flores e amiga da namorada debocha q...  \n",
              "66   mulher gravando para provar que não precisa de...  \n",
              "\n",
              "[5 rows x 38 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "o5Rw8VbLYpOw"
      },
      "outputs": [],
      "source": [
        "# Remove textos vazios ou contendo apenas espaços em branco\n",
        "train_sentences = [text for text in train_data['text'].tolist() if isinstance(text, str) and text.strip()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Execução do Grid Search\n",
        "\n",
        "os hiperparâmetros do modelo podem influenciar significativamente os resultados do modelo e uma escolha indevida poderia compremeter os resultados. Uma estratégia conhecida para evitar valores inadequados de hiperparâmetros é a Grid Search, que se trata de uma busca iterativa com parâmetros pré-selecionados. Os hiperparâmetros testados e a coerência gerada a partir de suas combinações estão visiveis na seção abaixo. A partir do melhor resultado encontrado a partir da busca extensiva, todos os dados foram integralmente submetidos a outra instância do algoritmo, usando-se os hiperpâmetros selecionados.\n",
        "\n",
        "Apesar de diversos hiperparâmetros estarem sendo avaliados, destaco aqui os modelos de pré-treino de embedding e o uso do TF-IDF para e UMAP para aprimorar e reduzir a dimensionalidade dos dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rNFzDlqiYpOv"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    \"embedding_model_name\": [\n",
        "        \"all-MiniLM-L6-v2\",\n",
        "        \"roberta\",\n",
        "        \"paraphrase-MiniLM-L6-v2\"\n",
        "    ],\n",
        "    \"reduction_model_name\": [\n",
        "        \"umap\"\n",
        "    ],\n",
        "    \"umap_params\": [\n",
        "        {\"n_neighbors\": 5, \"n_components\": 5, \"min_dist\": 0.1},\n",
        "        {\"n_neighbors\": 20, \"n_components\": 5, \"min_dist\": 0.1},\n",
        "        {\"n_neighbors\": 50, \"n_components\": 5, \"min_dist\": 0.1},\n",
        "        {\"n_neighbors\": 100, \"n_components\": 5, \"min_dist\": 0.1},\n",
        "        {\"n_neighbors\": 5, \"n_components\": 5, \"min_dist\": 0.5},\n",
        "        {\"n_neighbors\": 20, \"n_components\": 5, \"min_dist\": 0.5},\n",
        "        {\"n_neighbors\": 50, \"n_components\": 5, \"min_dist\": 0.5},\n",
        "        {\"n_neighbors\": 100, \"n_components\": 5, \"min_dist\": 0.5},\n",
        "    ],  # Parâmetros para UMAP\n",
        "    \"clustering_model_name\": [\n",
        "        \"hdbscan\",\n",
        "        # \"agglomerative\",\n",
        "        \"kmeans\"\n",
        "    ],\n",
        "    \"representation_model_name\": [\n",
        "        \"maximal_marginal_relevance\"\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "eZ6fKVfDYpOw"
      },
      "outputs": [],
      "source": [
        "def get_embedding_model(name):\n",
        "    \"\"\"Retrieve embedding model based on name.\"\"\"\n",
        "    models = {\n",
        "        \"all-MiniLM-L6-v2\": SentenceTransformer('all-MiniLM-L6-v2'),\n",
        "        \"roberta\": SentenceTransformer('roberta-base-nli-stsb-mean-tokens'),\n",
        "        \"paraphrase-MiniLM-L6-v2\": SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "    }\n",
        "    return models.get(name, None)\n",
        "\n",
        "def get_reduction_model(reduction_model_name, umap_params=None):\n",
        "    \"\"\"\n",
        "    Função para retornar o modelo de redução de dimensionalidade baseado no nome.\n",
        "    \"\"\"\n",
        "    if reduction_model_name == \"umap\":\n",
        "        import umap\n",
        "        return umap.UMAP(\n",
        "            n_neighbors=umap_params.get(\"n_neighbors\", 15),\n",
        "            n_components=umap_params.get(\"n_components\", 2),\n",
        "            min_dist=umap_params.get(\"min_dist\", 0.1),\n",
        "            random_state=42,\n",
        "            low_memory=True\n",
        "        )\n",
        "    raise ValueError(f\"Reduction model '{reduction_model_name}' não suportado.\")\n",
        "\n",
        "def get_clustering_model(name, min_cluster_size):\n",
        "    \"\"\"Retrieve clustering model based on name.\"\"\"\n",
        "    if name == \"hdbscan\":\n",
        "        return HDBSCAN(min_cluster_size=min_cluster_size, prediction_data=True)\n",
        "    elif name == \"agglomerative\":\n",
        "        return AgglomerativeClustering(n_clusters=min_cluster_size)\n",
        "    elif name == \"kmeans\":\n",
        "        return KMeans(n_clusters=min_cluster_size, random_state=42)\n",
        "    return None\n",
        "\n",
        "def get_representation_model(name, diversity):\n",
        "    \"\"\"Retrieve representation model.\"\"\"\n",
        "    if name == \"mmr\":\n",
        "        return MaximalMarginalRelevance(diversity=diversity)\n",
        "    elif name == \"keybert\":\n",
        "        return KeyBERTInspired(diversity=diversity)\n",
        "    elif name == \"openai\":\n",
        "        from config import OPENAI_KEY\n",
        "        client = openai.OpenAI(api_key=OPENAI_KEY)\n",
        "        return OpenAI(client, model=\"gpt-3.5-turbo\", chat=True)\n",
        "    return None\n",
        "\n",
        "def calculate_coherence(topic_model, sentences):\n",
        "    \"\"\"Calculate coherence score for a BERTopic model.\"\"\"\n",
        "    texts = [sentence.split() for sentence in sentences]\n",
        "    dictionary = Dictionary(texts)\n",
        "    topic_ids = topic_model.get_topics().keys()\n",
        "    topics = [[word for word, _ in topic_model.get_topics()[topic_id]] for topic_id in topic_ids]\n",
        "    coherence_model = CoherenceModel(\n",
        "        topics=topics,\n",
        "        texts=texts,\n",
        "        dictionary=dictionary,\n",
        "        coherence=\"c_v\"\n",
        "    )\n",
        "    return coherence_model.get_coherence()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8AkqRvk1YpOw"
      },
      "outputs": [],
      "source": [
        "# Configuração de logging\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "\n",
        "def perform_grid_search(sentences, param_grid, results_file):\n",
        "    \"\"\"\n",
        "    Realiza busca em grade para hiperparâmetros de BERTopic ou utiliza os melhores parâmetros salvos.\n",
        "    \"\"\"\n",
        "    best_coherence = -np.inf\n",
        "\n",
        "    # Calcula todas as combinações de parâmetros\n",
        "    all_combinations = list(product(*param_grid.values()))\n",
        "    total_combinations = len(all_combinations)\n",
        "\n",
        "    try:\n",
        "        results_df = pd.read_csv(results_file)\n",
        "        if not results_df.empty:\n",
        "            logging.info(\"\\n=== Alguns modelos já foram previamente calculados ===\")\n",
        "\n",
        "            # Verifica se todas as combinações já foram calculadas\n",
        "            calculated_combinations = results_df[[\n",
        "                \"embedding_model\", \"reduction_model\", \"umap_params\",\n",
        "                \"clustering_model\", \"representation_model\"\n",
        "            ]].drop_duplicates().shape[0]\n",
        "\n",
        "            if calculated_combinations == total_combinations:\n",
        "                logging.info(\"Todas as combinações de parâmetros já foram calculadas.\")\n",
        "    except FileNotFoundError:\n",
        "        results_df = pd.DataFrame(columns=[\n",
        "            \"embedding_model\", \"reduction_model\", \"umap_params\",\n",
        "            \"clustering_model\", \"representation_model\", \"coherence\"\n",
        "        ])\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Erro ao carregar os melhores parâmetros: {e}\")\n",
        "\n",
        "    # Caso as combinações não estejam completas, realiza a busca em grade\n",
        "    logging.info(\"\\n=== Starting Grid Search ===\")\n",
        "    logging.info(f\"Total parameter combinations: {total_combinations}\")\n",
        "\n",
        "    with tqdm(total=total_combinations, desc=\"Grid Search Progress\", unit=\"combination\") as pbar:\n",
        "        if not results_df.empty:\n",
        "            already_calculated = set(\n",
        "                tuple(row) for row in results_df[[\n",
        "                    \"embedding_model\", \"reduction_model\", \"umap_params\",\n",
        "                    \"clustering_model\", \"representation_model\"\n",
        "                ]].drop_duplicates().itertuples(index=False, name=None)\n",
        "            )\n",
        "        else:\n",
        "            already_calculated = set()\n",
        "\n",
        "        for params in all_combinations:\n",
        "            param_key = {\n",
        "                \"embedding_model\": params[0],\n",
        "                \"reduction_model\": params[1],\n",
        "                \"umap_params\": str(params[2]),\n",
        "                \"clustering_model\": params[3],\n",
        "                \"representation_model\": params[4]\n",
        "            }\n",
        "\n",
        "            if tuple(param_key.values()) in already_calculated:\n",
        "                existing_coherence = results_df.loc[\n",
        "                    (results_df[list(param_key)] == pd.Series(param_key)).all(axis=1), \"coherence\"\n",
        "                ].values[0]\n",
        "                logging.info(f\"Modelo já calculado: {param_key} | Coherence: {existing_coherence}\")\n",
        "                pbar.update(1)\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                logging.info(f\"Calculando novos parâmetros: {param_key}\")\n",
        "                embedding_model = get_embedding_model(param_key[\"embedding_model\"])\n",
        "                reduction_model = get_reduction_model(param_key[\"reduction_model\"], eval(param_key[\"umap_params\"]))\n",
        "                clustering_model = get_clustering_model(param_key[\"clustering_model\"], 30)\n",
        "                tfidf_vectorizer = TfidfVectorizer(stop_words='english', smooth_idf=True)\n",
        "                representation_model = get_representation_model(param_key[\"representation_model\"], None)\n",
        "\n",
        "                logging.info(\"Initializing model...\")\n",
        "                topic_model = BERTopic(\n",
        "                    n_gram_range=2,\n",
        "                    language=\"english\",\n",
        "                    umap_model=reduction_model,\n",
        "                    hdbscan_model=clustering_model,\n",
        "                    vectorizer_model=tfidf_vectorizer,\n",
        "                    representation_model=representation_model,\n",
        "                    embedding_model=embedding_model,\n",
        "                    min_topic_size=100,\n",
        "                )\n",
        "\n",
        "                logging.info(\"Fitting model...\")\n",
        "                topic_model.fit_transform(sentences)\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Erro com parâmetros {param_key}: {e}\")\n",
        "                pbar.update(1)\n",
        "                continue\n",
        "\n",
        "            logging.info(\"Calculating coherence...\")\n",
        "            coherence_score = calculate_coherence(topic_model, sentences)\n",
        "            new_result = {**param_key, \"coherence\": coherence_score}\n",
        "            results_df = pd.concat([results_df, pd.DataFrame([new_result])], ignore_index=True)\n",
        "            results_df.to_csv(results_file, index=False)\n",
        "\n",
        "            if coherence_score > best_coherence:\n",
        "                best_coherence = coherence_score\n",
        "\n",
        "            del embedding_model, reduction_model, clustering_model, tfidf_vectorizer, representation_model, topic_model\n",
        "            gc.collect()\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "    return results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (2.7.0)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (0.30.2)\n",
            "Requirement already satisfied: Pillow in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: colorama in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.24.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
            "[notice] To update, run: C:\\Users\\vmart\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "zntmFYVyiAjc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-14 19:27:08,391 - INFO - \n",
            "=== Starting Grid Search ===\n",
            "2025-06-14 19:27:08,391 - INFO - Total parameter combinations: 48\n",
            "Grid Search Progress:   0%|          | 0/48 [00:00<?, ?combination/s]2025-06-14 19:27:08,393 - INFO - Calculando novos parâmetros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:27:08,397 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:27:08,398 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:27:18,471 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:27:38,624 - ERROR - Erro com parâmetros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:   2%|▏         | 1/48 [00:30<23:40, 30.23s/combination]2025-06-14 19:27:38,626 - INFO - Calculando novos parâmetros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:27:38,631 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:27:38,632 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:27:48,697 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:28:08,779 - ERROR - Erro com parâmetros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:   4%|▍         | 2/48 [01:00<23:08, 30.19s/combination]2025-06-14 19:28:08,782 - INFO - Calculando novos parâmetros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:28:08,788 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:28:08,788 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:28:18,849 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:28:39,006 - ERROR - Erro com parâmetros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:   6%|▋         | 3/48 [01:30<22:39, 30.21s/combination]2025-06-14 19:28:39,011 - INFO - Calculando novos parâmetros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:28:39,016 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:28:39,017 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:28:49,064 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:29:09,183 - ERROR - Erro com parâmetros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:   8%|▊         | 4/48 [02:00<22:08, 30.19s/combination]2025-06-14 19:29:09,185 - INFO - Calculando novos parâmetros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:29:09,188 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:29:09,189 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:29:19,266 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:29:39,361 - ERROR - Erro com parâmetros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:  10%|█         | 5/48 [02:30<21:38, 30.19s/combination]2025-06-14 19:29:39,363 - INFO - Calculando novos parâmetros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:29:39,367 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:29:39,368 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:29:49,427 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:30:09,578 - ERROR - Erro com parâmetros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:  12%|█▎        | 6/48 [03:01<21:08, 30.20s/combination]2025-06-14 19:30:09,582 - INFO - Calculando novos parâmetros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:30:09,589 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:30:09,590 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:30:19,654 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:30:39,764 - ERROR - Erro com parâmetros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:  15%|█▍        | 7/48 [03:31<20:37, 30.19s/combination]2025-06-14 19:30:39,768 - INFO - Calculando novos parâmetros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:30:39,774 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:30:39,775 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:30:49,827 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:31:09,952 - ERROR - Erro com parâmetros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:  17%|█▋        | 8/48 [04:01<20:07, 30.19s/combination]2025-06-14 19:31:09,955 - INFO - Calculando novos parâmetros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:31:09,961 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:31:09,963 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:31:20,043 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:31:40,169 - ERROR - Erro com parâmetros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:  19%|█▉        | 9/48 [04:31<19:37, 30.20s/combination]2025-06-14 19:31:40,172 - INFO - Calculando novos parâmetros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:31:40,180 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:31:40,181 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:31:50,239 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:32:10,318 - ERROR - Erro com parâmetros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:  21%|██        | 10/48 [05:01<19:06, 30.18s/combination]2025-06-14 19:32:10,319 - INFO - Calculando novos parâmetros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:32:10,323 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:32:10,324 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:32:20,389 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:32:35,621 - ERROR - Erro com parâmetros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}: Unrecognized model in sentence-transformers/all-MiniLM-L6-v2. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, aria, aria_text, audio-spectrogram-transformer, autoformer, aya_vision, bamba, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, cohere2, colpali, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dab-detr, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deepseek_v3, deformable_detr, deit, depth_anything, depth_pro, deta, detr, diffllama, dinat, dinov2, dinov2_with_registers, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, emu3, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, gemma3, gemma3_text, git, glm, glm4, glpn, got_ocr2, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, granitemoeshared, granitevision, graphormer, grounding-dino, groupvit, helium, hiera, hubert, ibert, idefics, idefics2, idefics3, idefics3_vision, ijepa, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llama4, llama4_text, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mistral3, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, modernbert, moonshine, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phi4_multimodal, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prompt_depth_anything, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_5_vl, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, qwen3, qwen3_moe, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rt_detr_v2, rwkv, sam, sam_vision_model, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, shieldgemma2, siglip, siglip2, siglip_vision_model, smolvlm, smolvlm_vision, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superglue, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, textnet, time_series_transformer, timesformer, timm_backbone, timm_wrapper, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vitpose, vitpose_backbone, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zamba2, zoedepth\n",
            "Grid Search Progress:  23%|██▎       | 11/48 [05:27<17:41, 28.69s/combination]2025-06-14 19:32:35,622 - INFO - Calculando novos parâmetros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:32:35,625 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:32:35,626 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:32:45,674 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:33:05,779 - ERROR - Erro com parâmetros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:  25%|██▌       | 12/48 [05:57<17:28, 29.14s/combination]2025-06-14 19:33:05,782 - INFO - Calculando novos parâmetros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:33:05,787 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:33:05,788 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:33:15,827 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:33:35,952 - ERROR - Erro com parâmetros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:  27%|██▋       | 13/48 [06:27<17:10, 29.45s/combination]2025-06-14 19:33:35,956 - INFO - Calculando novos parâmetros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:33:35,962 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:33:35,963 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:33:46,023 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:34:06,148 - ERROR - Erro com parâmetros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:  29%|██▉       | 14/48 [06:57<16:48, 29.68s/combination]2025-06-14 19:34:06,150 - INFO - Calculando novos parâmetros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:34:06,153 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:34:06,154 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:34:16,212 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:34:31,626 - ERROR - Erro com parâmetros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:  31%|███▏      | 15/48 [07:23<15:37, 28.41s/combination]2025-06-14 19:34:31,628 - INFO - Calculando novos parâmetros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:34:31,635 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:34:31,637 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:34:41,685 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 22:35:02,155 - ERROR - Erro com parâmetros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:  33%|███▎      | 16/48 [3:07:53<29:09:15, 3279.85s/combination]2025-06-14 22:35:02,156 - INFO - Calculando novos parâmetros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 22:35:02,159 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 22:35:02,160 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "2025-06-15 11:18:50,586 - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "2025-06-15 11:18:56,227 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:18:56,228 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "2025-06-15 11:18:58,796 - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "2025-06-15 11:19:20,080 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:19:20,080 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "2025-06-15 11:19:22,860 - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "2025-06-15 11:19:29,108 - INFO - Initializing model...\n",
            "2025-06-15 11:19:29,109 - INFO - Fitting model...\n",
            "2025-06-15 11:19:42,300 - INFO - Calculating coherence...\n",
            "2025-06-15 11:19:42,302 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:19:42,308 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:19:42,309 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:19:42.309954', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:19:42,310 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:19:45,082 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:19:45,085 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:19:47,209 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:19:47,218 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  35%|███▌      | 17/48 [15:52:39<138:33:50, 16091.31s/combination]2025-06-15 11:19:47,511 - INFO - Calculando novos parâmetros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:19:47,514 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:19:47,515 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:19:49,078 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:19:49,079 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:19:51,024 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:19:51,025 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:19:53,938 - INFO - Initializing model...\n",
            "2025-06-15 11:19:53,939 - INFO - Fitting model...\n",
            "  File \"C:\\Users\\vmart\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
            "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n",
            "2025-06-15 11:20:00,634 - INFO - Calculating coherence...\n",
            "2025-06-15 11:20:00,635 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:20:00,641 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:20:00,642 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:20:00.642579', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:20:00,643 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:20:09,220 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:20:09,222 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:20:09,407 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:20:09,417 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  38%|███▊      | 18/48 [15:53:01<93:51:22, 11262.74s/combination] 2025-06-15 11:20:09,818 - INFO - Calculando novos parâmetros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:20:09,821 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:20:09,822 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:20:11,709 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:20:11,709 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:20:15,088 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:20:15,089 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:20:17,136 - INFO - Initializing model...\n",
            "2025-06-15 11:20:17,137 - INFO - Fitting model...\n",
            "2025-06-15 11:20:23,790 - INFO - Calculating coherence...\n",
            "2025-06-15 11:20:23,792 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:20:23,798 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:20:23,799 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:20:23.799193', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:20:23,800 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:20:24,990 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:20:24,993 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:20:26,910 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:20:26,916 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  40%|███▉      | 19/48 [15:53:18<63:31:13, 7885.30s/combination] 2025-06-15 11:20:27,240 - INFO - Calculando novos parâmetros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:20:27,244 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:20:27,245 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:20:30,148 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:20:30,149 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:20:32,193 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:20:32,194 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:20:34,182 - INFO - Initializing model...\n",
            "2025-06-15 11:20:34,184 - INFO - Fitting model...\n",
            "2025-06-15 11:20:41,370 - INFO - Calculating coherence...\n",
            "2025-06-15 11:20:41,372 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:20:41,381 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:20:41,382 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:20:41.382947', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:20:41,383 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:20:50,844 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:20:50,845 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:20:51,020 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:20:51,032 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  42%|████▏     | 20/48 [15:53:43<42:58:22, 5525.10s/combination]2025-06-15 11:20:51,489 - INFO - Calculando novos parâmetros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:20:51,491 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:20:51,493 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:20:53,701 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:20:53,702 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:20:55,848 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:20:55,848 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:20:57,996 - INFO - Initializing model...\n",
            "2025-06-15 11:20:57,998 - INFO - Fitting model...\n",
            "2025-06-15 11:21:04,586 - INFO - Calculating coherence...\n",
            "2025-06-15 11:21:04,587 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:21:04,594 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:21:04,595 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:21:04.595181', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:21:04,596 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:21:05,744 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:21:05,747 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:21:07,646 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:21:07,651 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  44%|████▍     | 21/48 [15:53:59<29:02:12, 3871.59s/combination]2025-06-15 11:21:07,955 - INFO - Calculando novos parâmetros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:21:07,958 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:21:07,959 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:21:09,881 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:21:09,882 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:21:11,821 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:21:11,822 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:21:13,665 - INFO - Initializing model...\n",
            "2025-06-15 11:21:13,668 - INFO - Fitting model...\n",
            "2025-06-15 11:21:20,793 - INFO - Calculating coherence...\n",
            "2025-06-15 11:21:20,795 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:21:20,805 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:21:20,806 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:21:20.806464', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:21:20,808 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:21:30,317 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:21:30,318 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:21:30,482 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:21:30,494 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  46%|████▌     | 22/48 [15:54:22<19:37:10, 2716.56s/combination]2025-06-15 11:21:30,949 - INFO - Calculando novos parâmetros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:21:30,952 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:21:30,953 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:21:32,827 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:21:32,827 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:21:35,075 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:21:35,076 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:21:37,115 - INFO - Initializing model...\n",
            "2025-06-15 11:21:37,116 - INFO - Fitting model...\n",
            "2025-06-15 11:21:44,365 - INFO - Calculating coherence...\n",
            "2025-06-15 11:21:44,367 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:21:44,373 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:21:44,374 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:21:44.374194', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:21:44,375 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:21:45,569 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:21:45,571 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:21:47,623 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:21:47,629 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  48%|████▊     | 23/48 [15:54:39<13:14:21, 1906.46s/combination]2025-06-15 11:21:47,931 - INFO - Calculando novos parâmetros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:21:47,935 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:21:47,936 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:21:50,435 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:21:50,435 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:21:52,579 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:21:52,580 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:21:54,421 - INFO - Initializing model...\n",
            "2025-06-15 11:21:54,424 - INFO - Fitting model...\n",
            "2025-06-15 11:22:06,237 - INFO - Calculating coherence...\n",
            "2025-06-15 11:22:06,241 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:22:06,264 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:22:06,272 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:22:06.272344', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:22:06,280 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:22:18,399 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:22:18,402 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:22:18,615 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:22:18,627 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  50%|█████     | 24/48 [15:55:11<8:57:33, 1343.89s/combination] 2025-06-15 11:22:19,526 - INFO - Calculando novos parâmetros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:22:19,535 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:22:19,537 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:22:21,405 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:22:21,406 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:22:23,819 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:22:23,821 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:22:25,960 - INFO - Initializing model...\n",
            "2025-06-15 11:22:25,962 - INFO - Fitting model...\n",
            "2025-06-15 11:23:20,690 - INFO - Calculating coherence...\n",
            "2025-06-15 11:23:20,693 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:23:20,709 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:23:20,710 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:23:20.710637', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:23:20,712 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:23:22,175 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:23:22,177 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:23:24,159 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:23:24,170 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  52%|█████▏    | 25/48 [15:56:16<6:08:06, 960.30s/combination] 2025-06-15 11:23:24,948 - INFO - Calculando novos parâmetros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:23:24,956 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:23:24,958 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:23:26,676 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:23:26,677 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:23:28,798 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:23:28,955 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:23:30,621 - INFO - Initializing model...\n",
            "2025-06-15 11:23:30,622 - INFO - Fitting model...\n",
            "2025-06-15 11:24:37,268 - INFO - Calculating coherence...\n",
            "2025-06-15 11:24:37,271 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:24:37,282 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:24:37,284 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:24:37.284006', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:24:37,289 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:24:51,474 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:24:51,479 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:24:52,030 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:24:52,055 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  54%|█████▍    | 26/48 [15:57:45<4:16:15, 698.88s/combination]2025-06-15 11:24:53,915 - INFO - Calculando novos parâmetros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:24:53,926 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:24:53,927 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:24:55,989 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:24:55,991 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:24:58,209 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:24:58,210 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:25:00,496 - INFO - Initializing model...\n",
            "2025-06-15 11:25:00,498 - INFO - Fitting model...\n",
            "2025-06-15 11:26:15,239 - INFO - Calculating coherence...\n",
            "2025-06-15 11:26:15,241 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:26:15,353 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:26:15,354 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:26:15.354622', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:26:15,356 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:26:17,845 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:26:17,848 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:26:19,544 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:26:19,556 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  56%|█████▋    | 27/48 [15:59:12<3:00:18, 515.15s/combination]2025-06-15 11:26:20,407 - INFO - Calculando novos parâmetros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:26:20,415 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:26:20,416 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:26:22,019 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:26:22,021 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:26:24,365 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:26:24,366 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:26:26,321 - INFO - Initializing model...\n",
            "2025-06-15 11:26:26,322 - INFO - Fitting model...\n",
            "2025-06-15 11:27:25,121 - INFO - Calculating coherence...\n",
            "2025-06-15 11:27:25,124 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:27:25,143 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:27:25,145 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:27:25.145949', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:27:25,149 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:27:36,150 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:27:36,154 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:27:36,413 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:27:36,428 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  58%|█████▊    | 28/48 [16:00:28<2:07:53, 383.68s/combination]2025-06-15 11:27:37,342 - INFO - Calculando novos parâmetros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:27:37,352 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:27:37,353 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:27:38,948 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:27:38,950 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:27:41,373 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:27:41,374 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:27:43,716 - INFO - Initializing model...\n",
            "2025-06-15 11:27:43,718 - INFO - Fitting model...\n",
            "2025-06-15 11:28:36,789 - INFO - Calculating coherence...\n",
            "2025-06-15 11:28:36,792 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:28:36,809 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:28:36,812 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:28:36.812283', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:28:36,813 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:28:38,185 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:28:38,187 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:28:39,906 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:28:39,914 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  60%|██████    | 29/48 [16:01:32<1:31:02, 287.51s/combination]2025-06-15 11:28:40,480 - INFO - Calculando novos parâmetros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:28:40,490 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:28:40,492 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:28:42,610 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:28:42,611 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:28:44,840 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:28:44,841 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:28:46,800 - INFO - Initializing model...\n",
            "2025-06-15 11:28:46,802 - INFO - Fitting model...\n",
            "2025-06-15 11:29:47,725 - INFO - Calculating coherence...\n",
            "2025-06-15 11:29:47,729 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:29:47,745 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:29:47,747 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:29:47.747692', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:29:47,750 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:29:59,464 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:29:59,467 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:29:59,732 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:29:59,746 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  62%|██████▎   | 30/48 [16:02:52<1:07:35, 225.31s/combination]2025-06-15 11:30:00,666 - INFO - Calculando novos parâmetros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:30:00,675 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:30:00,676 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:30:02,995 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:30:02,996 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:30:05,351 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:30:05,352 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:30:07,492 - INFO - Initializing model...\n",
            "2025-06-15 11:30:07,495 - INFO - Fitting model...\n",
            "2025-06-15 11:30:59,932 - INFO - Calculating coherence...\n",
            "2025-06-15 11:30:59,935 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:31:00,060 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:31:00,062 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:31:00.062386', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:31:00,064 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:31:01,428 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:31:01,431 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:31:03,379 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:31:03,386 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  65%|██████▍   | 31/48 [16:03:55<50:05, 176.79s/combination]  2025-06-15 11:31:04,226 - INFO - Calculando novos parâmetros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:31:04,309 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:31:04,311 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:31:05,951 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:31:05,953 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:31:08,035 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:31:08,036 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:31:09,915 - INFO - Initializing model...\n",
            "2025-06-15 11:31:09,917 - INFO - Fitting model...\n",
            "2025-06-15 11:31:58,494 - INFO - Calculating coherence...\n",
            "2025-06-15 11:31:58,497 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:31:58,516 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:31:58,517 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:31:58.517577', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:31:58,522 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:32:09,245 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:32:09,249 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:32:09,478 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:32:09,491 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  67%|██████▋   | 32/48 [16:05:02<38:17, 143.61s/combination]2025-06-15 11:32:10,413 - INFO - Calculando novos parâmetros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:32:10,422 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:32:10,424 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:32:12,341 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:32:12,342 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:32:14,688 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:32:14,690 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:32:16,828 - INFO - Initializing model...\n",
            "2025-06-15 11:32:16,830 - INFO - Fitting model...\n",
            "2025-06-15 11:32:21,101 - INFO - Calculating coherence...\n",
            "2025-06-15 11:32:21,104 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:32:21,122 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:32:21,125 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:32:21.125265', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:32:21,127 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:32:22,355 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:32:22,358 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:32:24,305 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:32:24,317 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  69%|██████▉   | 33/48 [16:05:16<26:13, 104.93s/combination]2025-06-15 11:32:25,110 - INFO - Calculando novos parâmetros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:32:25,118 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:32:25,119 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:32:27,180 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:32:27,181 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:32:29,843 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:32:29,845 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:32:31,984 - INFO - Initializing model...\n",
            "2025-06-15 11:32:31,986 - INFO - Fitting model...\n",
            "2025-06-15 11:32:37,094 - INFO - Calculating coherence...\n",
            "2025-06-15 11:32:37,097 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:32:37,116 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:32:37,117 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:32:37.117982', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:32:37,123 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:32:48,004 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:32:48,007 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:32:48,298 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:32:48,319 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  71%|███████   | 34/48 [16:05:40<18:49, 80.71s/combination] 2025-06-15 11:32:49,296 - INFO - Calculando novos parâmetros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:32:49,306 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:32:49,307 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:32:51,344 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:32:51,345 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:32:53,541 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:32:53,543 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:32:55,501 - INFO - Initializing model...\n",
            "2025-06-15 11:32:55,503 - INFO - Fitting model...\n",
            "2025-06-15 11:33:03,473 - INFO - Calculating coherence...\n",
            "2025-06-15 11:33:03,476 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:33:03,494 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:33:03,495 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:33:03.495271', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:33:03,497 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:33:04,808 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:33:04,811 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:33:06,655 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:33:06,662 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  73%|███████▎  | 35/48 [16:05:58<13:24, 61.90s/combination]2025-06-15 11:33:07,295 - INFO - Calculando novos parâmetros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:33:07,305 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:33:07,306 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:33:09,370 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:33:09,371 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:33:11,727 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:33:11,728 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:33:13,521 - INFO - Initializing model...\n",
            "2025-06-15 11:33:13,523 - INFO - Fitting model...\n",
            "2025-06-15 11:33:20,538 - INFO - Calculating coherence...\n",
            "2025-06-15 11:33:20,541 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:33:20,562 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:33:20,563 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:33:20.563563', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:33:20,566 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:33:31,757 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:33:31,760 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:33:32,030 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:33:32,047 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  75%|███████▌  | 36/48 [16:06:24<10:12, 51.05s/combination]2025-06-15 11:33:33,023 - INFO - Calculando novos parâmetros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:33:33,033 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:33:33,034 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:33:34,970 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:33:34,971 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:33:37,020 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:33:37,021 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:33:39,058 - INFO - Initializing model...\n",
            "2025-06-15 11:33:39,060 - INFO - Fitting model...\n",
            "2025-06-15 11:33:44,373 - INFO - Calculating coherence...\n",
            "2025-06-15 11:33:44,377 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:33:44,398 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:33:44,400 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:33:44.400007', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:33:44,404 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:33:45,796 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:33:45,798 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:33:47,759 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:33:47,769 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  77%|███████▋  | 37/48 [16:06:40<07:23, 40.35s/combination]2025-06-15 11:33:48,419 - INFO - Calculando novos parâmetros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:33:48,432 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:33:48,434 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:33:50,724 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:33:50,726 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:33:52,689 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:33:52,690 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:33:54,631 - INFO - Initializing model...\n",
            "2025-06-15 11:33:54,633 - INFO - Fitting model...\n",
            "2025-06-15 11:34:00,592 - INFO - Calculating coherence...\n",
            "2025-06-15 11:34:00,595 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:34:00,615 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:34:00,617 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:34:00.617797', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:34:00,623 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:34:11,892 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:34:11,895 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:34:12,128 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:34:12,144 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  79%|███████▉  | 38/48 [16:07:04<05:56, 35.63s/combination]2025-06-15 11:34:13,034 - INFO - Calculando novos parâmetros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:34:13,043 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:34:13,045 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:34:15,318 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:34:15,319 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:34:19,619 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:34:19,621 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:34:21,660 - INFO - Initializing model...\n",
            "2025-06-15 11:34:21,661 - INFO - Fitting model...\n",
            "2025-06-15 11:34:27,513 - INFO - Calculating coherence...\n",
            "2025-06-15 11:34:27,517 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:34:27,538 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:34:27,540 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:34:27.540711', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:34:27,543 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:34:28,852 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:34:28,854 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:34:30,766 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:34:30,774 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  81%|████████▏ | 39/48 [16:07:23<04:34, 30.45s/combination]2025-06-15 11:34:31,405 - INFO - Calculando novos parâmetros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:34:31,413 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:34:31,415 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:34:33,100 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:34:33,102 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:34:35,536 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:34:35,538 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:34:37,532 - INFO - Initializing model...\n",
            "2025-06-15 11:34:37,534 - INFO - Fitting model...\n",
            "2025-06-15 11:34:43,167 - INFO - Calculating coherence...\n",
            "2025-06-15 11:34:43,171 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:34:43,223 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:34:43,233 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:34:43.231917', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:34:43,239 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:34:53,896 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:34:53,900 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:34:54,140 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:34:54,158 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  83%|████████▎ | 40/48 [16:07:46<03:47, 28.41s/combination]2025-06-15 11:34:55,046 - INFO - Calculando novos parâmetros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:34:55,055 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:34:55,057 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:34:57,526 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:34:57,529 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:34:59,912 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:34:59,914 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:35:01,799 - INFO - Initializing model...\n",
            "2025-06-15 11:35:01,801 - INFO - Fitting model...\n",
            "2025-06-15 11:35:10,542 - INFO - Calculating coherence...\n",
            "2025-06-15 11:35:10,545 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:35:10,562 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:35:10,563 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:35:10.563739', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:35:10,565 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:35:11,794 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:35:11,796 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:35:13,683 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:35:13,692 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  85%|████████▌ | 41/48 [16:08:05<02:59, 25.67s/combination]2025-06-15 11:35:14,340 - INFO - Calculando novos parâmetros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:35:14,349 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:35:14,350 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:35:16,438 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:35:16,440 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:35:18,804 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:35:18,805 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:35:20,845 - INFO - Initializing model...\n",
            "2025-06-15 11:35:20,847 - INFO - Fitting model...\n",
            "2025-06-15 11:35:25,618 - INFO - Calculating coherence...\n",
            "2025-06-15 11:35:25,620 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:35:25,641 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:35:25,642 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:35:25.642373', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:35:25,646 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:35:37,021 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:35:37,026 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:35:37,310 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:35:37,327 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  88%|████████▊ | 42/48 [16:08:30<02:31, 25.25s/combination]2025-06-15 11:35:38,587 - INFO - Calculando novos parâmetros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:35:38,596 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:35:38,597 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:35:40,585 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:35:40,587 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:35:42,873 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:35:42,875 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:35:44,653 - INFO - Initializing model...\n",
            "2025-06-15 11:35:44,657 - INFO - Fitting model...\n",
            "2025-06-15 11:35:49,878 - INFO - Calculating coherence...\n",
            "2025-06-15 11:35:49,882 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:35:49,900 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:35:49,903 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:35:49.903891', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:35:49,943 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:35:51,394 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:35:51,396 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:35:53,134 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:35:53,142 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  90%|████████▉ | 43/48 [16:08:45<01:50, 22.19s/combination]2025-06-15 11:35:53,659 - INFO - Calculando novos parâmetros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:35:53,668 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:35:53,670 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:35:55,615 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:35:55,617 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:35:57,721 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:35:57,722 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:35:59,762 - INFO - Initializing model...\n",
            "2025-06-15 11:35:59,764 - INFO - Fitting model...\n",
            "2025-06-15 11:36:04,300 - INFO - Calculating coherence...\n",
            "2025-06-15 11:36:04,304 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:36:04,324 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:36:04,326 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:36:04.326591', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:36:04,330 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:36:14,843 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:36:14,846 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:36:15,065 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:36:15,080 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  92%|█████████▏| 44/48 [16:09:07<01:28, 22.23s/combination]2025-06-15 11:36:15,990 - INFO - Calculando novos parâmetros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:36:15,998 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:36:16,000 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:36:18,406 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:36:18,407 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:36:20,558 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:36:20,560 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:36:22,702 - INFO - Initializing model...\n",
            "2025-06-15 11:36:22,704 - INFO - Fitting model...\n",
            "2025-06-15 11:36:27,176 - INFO - Calculating coherence...\n",
            "2025-06-15 11:36:27,179 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:36:27,199 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:36:27,202 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:36:27.202624', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:36:27,205 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:36:28,407 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:36:28,410 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:36:30,212 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:36:30,224 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  94%|█████████▍| 45/48 [16:09:22<01:00, 20.02s/combination]2025-06-15 11:36:30,838 - INFO - Calculando novos parâmetros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:36:30,848 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:36:30,849 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:36:33,306 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:36:33,307 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:36:35,611 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:36:35,613 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:36:37,753 - INFO - Initializing model...\n",
            "2025-06-15 11:36:37,755 - INFO - Fitting model...\n",
            "2025-06-15 11:36:43,250 - INFO - Calculating coherence...\n",
            "2025-06-15 11:36:43,253 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:36:43,273 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:36:43,275 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:36:43.275188', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:36:43,276 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:36:54,095 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:36:54,099 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:36:54,359 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:36:54,372 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  96%|█████████▌| 46/48 [16:09:46<00:42, 21.34s/combination]2025-06-15 11:36:55,266 - INFO - Calculando novos parâmetros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:36:55,275 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:36:55,276 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:36:57,243 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:36:57,245 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:36:59,675 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:36:59,676 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:37:01,512 - INFO - Initializing model...\n",
            "2025-06-15 11:37:01,514 - INFO - Fitting model...\n",
            "2025-06-15 11:37:06,763 - INFO - Calculating coherence...\n",
            "2025-06-15 11:37:06,765 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:37:06,783 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:37:06,793 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:37:06.793207', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:37:06,796 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:37:08,170 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:37:08,173 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:37:10,111 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:37:10,122 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  98%|█████████▊| 47/48 [16:10:02<00:19, 19.58s/combination]2025-06-15 11:37:10,740 - INFO - Calculando novos parâmetros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:37:10,751 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:37:10,752 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:37:12,781 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:37:12,783 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:37:15,138 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:37:15,140 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:37:17,276 - INFO - Initializing model...\n",
            "2025-06-15 11:37:17,279 - INFO - Fitting model...\n",
            "2025-06-15 11:37:23,663 - INFO - Calculating coherence...\n",
            "2025-06-15 11:37:23,666 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:37:23,685 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:37:23,687 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:37:23.687444', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:37:23,698 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:37:35,011 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:37:35,014 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:37:35,294 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:37:35,310 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress: 100%|██████████| 48/48 [16:10:27<00:00, 1213.08s/combination]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>embedding_model</th>\n",
              "      <th>reduction_model</th>\n",
              "      <th>umap_params</th>\n",
              "      <th>clustering_model</th>\n",
              "      <th>representation_model</th>\n",
              "      <th>coherence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.509318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.557656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.550874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.566453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.554769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.557588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.549375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.566509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.514351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.386301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.546947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.555407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.495577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.472862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.499655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.592118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.519590</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            embedding_model reduction_model  \\\n",
              "0                   roberta            umap   \n",
              "1                   roberta            umap   \n",
              "2                   roberta            umap   \n",
              "3                   roberta            umap   \n",
              "4                   roberta            umap   \n",
              "5                   roberta            umap   \n",
              "6                   roberta            umap   \n",
              "7                   roberta            umap   \n",
              "8                   roberta            umap   \n",
              "9                   roberta            umap   \n",
              "10                  roberta            umap   \n",
              "11                  roberta            umap   \n",
              "12                  roberta            umap   \n",
              "13                  roberta            umap   \n",
              "14                  roberta            umap   \n",
              "15                  roberta            umap   \n",
              "16  paraphrase-MiniLM-L6-v2            umap   \n",
              "17  paraphrase-MiniLM-L6-v2            umap   \n",
              "18  paraphrase-MiniLM-L6-v2            umap   \n",
              "19  paraphrase-MiniLM-L6-v2            umap   \n",
              "20  paraphrase-MiniLM-L6-v2            umap   \n",
              "21  paraphrase-MiniLM-L6-v2            umap   \n",
              "22  paraphrase-MiniLM-L6-v2            umap   \n",
              "23  paraphrase-MiniLM-L6-v2            umap   \n",
              "24  paraphrase-MiniLM-L6-v2            umap   \n",
              "25  paraphrase-MiniLM-L6-v2            umap   \n",
              "26  paraphrase-MiniLM-L6-v2            umap   \n",
              "27  paraphrase-MiniLM-L6-v2            umap   \n",
              "28  paraphrase-MiniLM-L6-v2            umap   \n",
              "29  paraphrase-MiniLM-L6-v2            umap   \n",
              "30  paraphrase-MiniLM-L6-v2            umap   \n",
              "31  paraphrase-MiniLM-L6-v2            umap   \n",
              "\n",
              "                                          umap_params clustering_model  \\\n",
              "0   {'n_neighbors': 5, 'n_components': 5, 'min_dis...          hdbscan   \n",
              "1   {'n_neighbors': 5, 'n_components': 5, 'min_dis...           kmeans   \n",
              "2   {'n_neighbors': 20, 'n_components': 5, 'min_di...          hdbscan   \n",
              "3   {'n_neighbors': 20, 'n_components': 5, 'min_di...           kmeans   \n",
              "4   {'n_neighbors': 50, 'n_components': 5, 'min_di...          hdbscan   \n",
              "5   {'n_neighbors': 50, 'n_components': 5, 'min_di...           kmeans   \n",
              "6   {'n_neighbors': 100, 'n_components': 5, 'min_d...          hdbscan   \n",
              "7   {'n_neighbors': 100, 'n_components': 5, 'min_d...           kmeans   \n",
              "8   {'n_neighbors': 5, 'n_components': 5, 'min_dis...          hdbscan   \n",
              "9   {'n_neighbors': 5, 'n_components': 5, 'min_dis...           kmeans   \n",
              "10  {'n_neighbors': 20, 'n_components': 5, 'min_di...          hdbscan   \n",
              "11  {'n_neighbors': 20, 'n_components': 5, 'min_di...           kmeans   \n",
              "12  {'n_neighbors': 50, 'n_components': 5, 'min_di...          hdbscan   \n",
              "13  {'n_neighbors': 50, 'n_components': 5, 'min_di...           kmeans   \n",
              "14  {'n_neighbors': 100, 'n_components': 5, 'min_d...          hdbscan   \n",
              "15  {'n_neighbors': 100, 'n_components': 5, 'min_d...           kmeans   \n",
              "16  {'n_neighbors': 5, 'n_components': 5, 'min_dis...          hdbscan   \n",
              "17  {'n_neighbors': 5, 'n_components': 5, 'min_dis...           kmeans   \n",
              "18  {'n_neighbors': 20, 'n_components': 5, 'min_di...          hdbscan   \n",
              "19  {'n_neighbors': 20, 'n_components': 5, 'min_di...           kmeans   \n",
              "20  {'n_neighbors': 50, 'n_components': 5, 'min_di...          hdbscan   \n",
              "21  {'n_neighbors': 50, 'n_components': 5, 'min_di...           kmeans   \n",
              "22  {'n_neighbors': 100, 'n_components': 5, 'min_d...          hdbscan   \n",
              "23  {'n_neighbors': 100, 'n_components': 5, 'min_d...           kmeans   \n",
              "24  {'n_neighbors': 5, 'n_components': 5, 'min_dis...          hdbscan   \n",
              "25  {'n_neighbors': 5, 'n_components': 5, 'min_dis...           kmeans   \n",
              "26  {'n_neighbors': 20, 'n_components': 5, 'min_di...          hdbscan   \n",
              "27  {'n_neighbors': 20, 'n_components': 5, 'min_di...           kmeans   \n",
              "28  {'n_neighbors': 50, 'n_components': 5, 'min_di...          hdbscan   \n",
              "29  {'n_neighbors': 50, 'n_components': 5, 'min_di...           kmeans   \n",
              "30  {'n_neighbors': 100, 'n_components': 5, 'min_d...          hdbscan   \n",
              "31  {'n_neighbors': 100, 'n_components': 5, 'min_d...           kmeans   \n",
              "\n",
              "          representation_model  coherence  \n",
              "0   maximal_marginal_relevance   0.377603  \n",
              "1   maximal_marginal_relevance   0.509318  \n",
              "2   maximal_marginal_relevance   0.377603  \n",
              "3   maximal_marginal_relevance   0.557656  \n",
              "4   maximal_marginal_relevance   0.377603  \n",
              "5   maximal_marginal_relevance   0.550874  \n",
              "6   maximal_marginal_relevance   0.377603  \n",
              "7   maximal_marginal_relevance   0.566453  \n",
              "8   maximal_marginal_relevance   0.377603  \n",
              "9   maximal_marginal_relevance   0.554769  \n",
              "10  maximal_marginal_relevance   0.377603  \n",
              "11  maximal_marginal_relevance   0.557588  \n",
              "12  maximal_marginal_relevance   0.377603  \n",
              "13  maximal_marginal_relevance   0.549375  \n",
              "14  maximal_marginal_relevance   0.377603  \n",
              "15  maximal_marginal_relevance   0.566509  \n",
              "16  maximal_marginal_relevance   0.377603  \n",
              "17  maximal_marginal_relevance   0.514351  \n",
              "18  maximal_marginal_relevance   0.386301  \n",
              "19  maximal_marginal_relevance   0.546947  \n",
              "20  maximal_marginal_relevance   0.377603  \n",
              "21  maximal_marginal_relevance   0.555407  \n",
              "22  maximal_marginal_relevance   0.377603  \n",
              "23  maximal_marginal_relevance   0.495577  \n",
              "24  maximal_marginal_relevance   0.377603  \n",
              "25  maximal_marginal_relevance   0.472862  \n",
              "26  maximal_marginal_relevance   0.377603  \n",
              "27  maximal_marginal_relevance   0.499655  \n",
              "28  maximal_marginal_relevance   0.377603  \n",
              "29  maximal_marginal_relevance   0.592118  \n",
              "30  maximal_marginal_relevance   0.377603  \n",
              "31  maximal_marginal_relevance   0.519590  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "perform_grid_search(train_sentences, param_grid, results_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>embedding_model</th>\n",
              "      <th>reduction_model</th>\n",
              "      <th>umap_params</th>\n",
              "      <th>clustering_model</th>\n",
              "      <th>representation_model</th>\n",
              "      <th>coherence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.592118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.566509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.566453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.557656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.557588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.555407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.554769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.550874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.549375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.546947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.519590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.514351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.509318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.499655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.495577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.472862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.386301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            embedding_model reduction_model  \\\n",
              "29  paraphrase-MiniLM-L6-v2            umap   \n",
              "15                  roberta            umap   \n",
              "7                   roberta            umap   \n",
              "3                   roberta            umap   \n",
              "11                  roberta            umap   \n",
              "21  paraphrase-MiniLM-L6-v2            umap   \n",
              "9                   roberta            umap   \n",
              "5                   roberta            umap   \n",
              "13                  roberta            umap   \n",
              "19  paraphrase-MiniLM-L6-v2            umap   \n",
              "31  paraphrase-MiniLM-L6-v2            umap   \n",
              "17  paraphrase-MiniLM-L6-v2            umap   \n",
              "1                   roberta            umap   \n",
              "27  paraphrase-MiniLM-L6-v2            umap   \n",
              "23  paraphrase-MiniLM-L6-v2            umap   \n",
              "25  paraphrase-MiniLM-L6-v2            umap   \n",
              "18  paraphrase-MiniLM-L6-v2            umap   \n",
              "28  paraphrase-MiniLM-L6-v2            umap   \n",
              "26  paraphrase-MiniLM-L6-v2            umap   \n",
              "22  paraphrase-MiniLM-L6-v2            umap   \n",
              "24  paraphrase-MiniLM-L6-v2            umap   \n",
              "30  paraphrase-MiniLM-L6-v2            umap   \n",
              "0                   roberta            umap   \n",
              "20  paraphrase-MiniLM-L6-v2            umap   \n",
              "14                  roberta            umap   \n",
              "12                  roberta            umap   \n",
              "10                  roberta            umap   \n",
              "8                   roberta            umap   \n",
              "6                   roberta            umap   \n",
              "4                   roberta            umap   \n",
              "2                   roberta            umap   \n",
              "16  paraphrase-MiniLM-L6-v2            umap   \n",
              "\n",
              "                                          umap_params clustering_model  \\\n",
              "29  {'n_neighbors': 50, 'n_components': 5, 'min_di...           kmeans   \n",
              "15  {'n_neighbors': 100, 'n_components': 5, 'min_d...           kmeans   \n",
              "7   {'n_neighbors': 100, 'n_components': 5, 'min_d...           kmeans   \n",
              "3   {'n_neighbors': 20, 'n_components': 5, 'min_di...           kmeans   \n",
              "11  {'n_neighbors': 20, 'n_components': 5, 'min_di...           kmeans   \n",
              "21  {'n_neighbors': 50, 'n_components': 5, 'min_di...           kmeans   \n",
              "9   {'n_neighbors': 5, 'n_components': 5, 'min_dis...           kmeans   \n",
              "5   {'n_neighbors': 50, 'n_components': 5, 'min_di...           kmeans   \n",
              "13  {'n_neighbors': 50, 'n_components': 5, 'min_di...           kmeans   \n",
              "19  {'n_neighbors': 20, 'n_components': 5, 'min_di...           kmeans   \n",
              "31  {'n_neighbors': 100, 'n_components': 5, 'min_d...           kmeans   \n",
              "17  {'n_neighbors': 5, 'n_components': 5, 'min_dis...           kmeans   \n",
              "1   {'n_neighbors': 5, 'n_components': 5, 'min_dis...           kmeans   \n",
              "27  {'n_neighbors': 20, 'n_components': 5, 'min_di...           kmeans   \n",
              "23  {'n_neighbors': 100, 'n_components': 5, 'min_d...           kmeans   \n",
              "25  {'n_neighbors': 5, 'n_components': 5, 'min_dis...           kmeans   \n",
              "18  {'n_neighbors': 20, 'n_components': 5, 'min_di...          hdbscan   \n",
              "28  {'n_neighbors': 50, 'n_components': 5, 'min_di...          hdbscan   \n",
              "26  {'n_neighbors': 20, 'n_components': 5, 'min_di...          hdbscan   \n",
              "22  {'n_neighbors': 100, 'n_components': 5, 'min_d...          hdbscan   \n",
              "24  {'n_neighbors': 5, 'n_components': 5, 'min_dis...          hdbscan   \n",
              "30  {'n_neighbors': 100, 'n_components': 5, 'min_d...          hdbscan   \n",
              "0   {'n_neighbors': 5, 'n_components': 5, 'min_dis...          hdbscan   \n",
              "20  {'n_neighbors': 50, 'n_components': 5, 'min_di...          hdbscan   \n",
              "14  {'n_neighbors': 100, 'n_components': 5, 'min_d...          hdbscan   \n",
              "12  {'n_neighbors': 50, 'n_components': 5, 'min_di...          hdbscan   \n",
              "10  {'n_neighbors': 20, 'n_components': 5, 'min_di...          hdbscan   \n",
              "8   {'n_neighbors': 5, 'n_components': 5, 'min_dis...          hdbscan   \n",
              "6   {'n_neighbors': 100, 'n_components': 5, 'min_d...          hdbscan   \n",
              "4   {'n_neighbors': 50, 'n_components': 5, 'min_di...          hdbscan   \n",
              "2   {'n_neighbors': 20, 'n_components': 5, 'min_di...          hdbscan   \n",
              "16  {'n_neighbors': 5, 'n_components': 5, 'min_dis...          hdbscan   \n",
              "\n",
              "          representation_model  coherence  \n",
              "29  maximal_marginal_relevance   0.592118  \n",
              "15  maximal_marginal_relevance   0.566509  \n",
              "7   maximal_marginal_relevance   0.566453  \n",
              "3   maximal_marginal_relevance   0.557656  \n",
              "11  maximal_marginal_relevance   0.557588  \n",
              "21  maximal_marginal_relevance   0.555407  \n",
              "9   maximal_marginal_relevance   0.554769  \n",
              "5   maximal_marginal_relevance   0.550874  \n",
              "13  maximal_marginal_relevance   0.549375  \n",
              "19  maximal_marginal_relevance   0.546947  \n",
              "31  maximal_marginal_relevance   0.519590  \n",
              "17  maximal_marginal_relevance   0.514351  \n",
              "1   maximal_marginal_relevance   0.509318  \n",
              "27  maximal_marginal_relevance   0.499655  \n",
              "23  maximal_marginal_relevance   0.495577  \n",
              "25  maximal_marginal_relevance   0.472862  \n",
              "18  maximal_marginal_relevance   0.386301  \n",
              "28  maximal_marginal_relevance   0.377603  \n",
              "26  maximal_marginal_relevance   0.377603  \n",
              "22  maximal_marginal_relevance   0.377603  \n",
              "24  maximal_marginal_relevance   0.377603  \n",
              "30  maximal_marginal_relevance   0.377603  \n",
              "0   maximal_marginal_relevance   0.377603  \n",
              "20  maximal_marginal_relevance   0.377603  \n",
              "14  maximal_marginal_relevance   0.377603  \n",
              "12  maximal_marginal_relevance   0.377603  \n",
              "10  maximal_marginal_relevance   0.377603  \n",
              "8   maximal_marginal_relevance   0.377603  \n",
              "6   maximal_marginal_relevance   0.377603  \n",
              "4   maximal_marginal_relevance   0.377603  \n",
              "2   maximal_marginal_relevance   0.377603  \n",
              "16  maximal_marginal_relevance   0.377603  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df = pd.read_csv(results_file)\n",
        "results_df.sort_values(by=\"coherence\", ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>video_id</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>channel_id</th>\n",
              "      <th>published_at</th>\n",
              "      <th>category_id</th>\n",
              "      <th>tags</th>\n",
              "      <th>view_count</th>\n",
              "      <th>...</th>\n",
              "      <th>concurrent_viewers</th>\n",
              "      <th>active_live_chat_id</th>\n",
              "      <th>recording_date</th>\n",
              "      <th>topicCategories</th>\n",
              "      <th>processing_status</th>\n",
              "      <th>parts_total</th>\n",
              "      <th>parts_processed</th>\n",
              "      <th>time_left_ms</th>\n",
              "      <th>processing_failure_reason</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>310</th>\n",
              "      <td>790</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q3ukRP_TUR4</td>\n",
              "      <td>MULHER DIZENDO QUE NÃO É NORMAL HOMEM MAIS VEL...</td>\n",
              "      <td>Olá! seja bem vindo a mais um video do canal, ...</td>\n",
              "      <td>UCRmNflJuD1TxLbRlDV08_7g</td>\n",
              "      <td>2025-05-09 12:04:47</td>\n",
              "      <td>24</td>\n",
              "      <td>['red pill', 'divorcio', 'pensão socio afetiva...</td>\n",
              "      <td>654</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://en.wikipedia.org/wiki/Humour']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>mulher dizendo que não é normal homem mais vel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1kIR_cBtHjM</td>\n",
              "      <td>esses homens estão PREFERINDO A SOLITUDE — e n...</td>\n",
              "      <td>💪 Use o cupom (CONSELHO) na Growth: https://ww...</td>\n",
              "      <td>UCX0VSzJ2z5l0C9wnwh5SoRw</td>\n",
              "      <td>2025-05-30 14:20:01</td>\n",
              "      <td>26</td>\n",
              "      <td>[]</td>\n",
              "      <td>20138</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://en.wikipedia.org/wiki/Society']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>esses homens estão preferindo solitude e não é...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335</th>\n",
              "      <td>335</td>\n",
              "      <td>370.0</td>\n",
              "      <td>pPyX0NtHjLw</td>\n",
              "      <td>Gritos, reclamações e raiva: o caminho mais rá...</td>\n",
              "      <td>#rafaelaires #antiotario #redpillbrasil\\n\\n🔥 P...</td>\n",
              "      <td>UCAYoI16-UkXemcnhC-kTvDQ</td>\n",
              "      <td>2025-05-07 21:01:00</td>\n",
              "      <td>22</td>\n",
              "      <td>[]</td>\n",
              "      <td>119</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gritos reclamações e raiva caminho mais rápido...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>425</th>\n",
              "      <td>425</td>\n",
              "      <td>466.0</td>\n",
              "      <td>MuScLmEv_ck</td>\n",
              "      <td>Se encontrou um Homem de valor, valorize! Apre...</td>\n",
              "      <td>#rafaelaires #antiotario #redpillbrasil\\n\\n🔥 P...</td>\n",
              "      <td>UCAYoI16-UkXemcnhC-kTvDQ</td>\n",
              "      <td>2025-05-02 15:00:41</td>\n",
              "      <td>22</td>\n",
              "      <td>[]</td>\n",
              "      <td>358</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://en.wikipedia.org/wiki/Lifestyle_(soc...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>se encontrou um homem de valor valorize aprend...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>228</td>\n",
              "      <td>255.0</td>\n",
              "      <td>w7tH6YIZyqc</td>\n",
              "      <td>MULHER DIZ QUE PAGA MARIDO PARA TER RELAÇÃO CO...</td>\n",
              "      <td>Olá! seja bem vindo a mais um video do canal, ...</td>\n",
              "      <td>UCRmNflJuD1TxLbRlDV08_7g</td>\n",
              "      <td>2025-05-15 01:55:09</td>\n",
              "      <td>24</td>\n",
              "      <td>['red pill', 'divorcio', 'pensão socio afetiva...</td>\n",
              "      <td>2718</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://en.wikipedia.org/wiki/Humour', 'http...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>mulher diz que paga marido para ter relação co...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 38 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0.1  Unnamed: 0     video_id  \\\n",
              "310           790         NaN  Q3ukRP_TUR4   \n",
              "11             11        12.0  1kIR_cBtHjM   \n",
              "335           335       370.0  pPyX0NtHjLw   \n",
              "425           425       466.0  MuScLmEv_ck   \n",
              "228           228       255.0  w7tH6YIZyqc   \n",
              "\n",
              "                                                 title  \\\n",
              "310  MULHER DIZENDO QUE NÃO É NORMAL HOMEM MAIS VEL...   \n",
              "11   esses homens estão PREFERINDO A SOLITUDE — e n...   \n",
              "335  Gritos, reclamações e raiva: o caminho mais rá...   \n",
              "425  Se encontrou um Homem de valor, valorize! Apre...   \n",
              "228  MULHER DIZ QUE PAGA MARIDO PARA TER RELAÇÃO CO...   \n",
              "\n",
              "                                           description  \\\n",
              "310  Olá! seja bem vindo a mais um video do canal, ...   \n",
              "11   💪 Use o cupom (CONSELHO) na Growth: https://ww...   \n",
              "335  #rafaelaires #antiotario #redpillbrasil\\n\\n🔥 P...   \n",
              "425  #rafaelaires #antiotario #redpillbrasil\\n\\n🔥 P...   \n",
              "228  Olá! seja bem vindo a mais um video do canal, ...   \n",
              "\n",
              "                   channel_id         published_at  category_id  \\\n",
              "310  UCRmNflJuD1TxLbRlDV08_7g  2025-05-09 12:04:47           24   \n",
              "11   UCX0VSzJ2z5l0C9wnwh5SoRw  2025-05-30 14:20:01           26   \n",
              "335  UCAYoI16-UkXemcnhC-kTvDQ  2025-05-07 21:01:00           22   \n",
              "425  UCAYoI16-UkXemcnhC-kTvDQ  2025-05-02 15:00:41           22   \n",
              "228  UCRmNflJuD1TxLbRlDV08_7g  2025-05-15 01:55:09           24   \n",
              "\n",
              "                                                  tags  view_count  ...  \\\n",
              "310  ['red pill', 'divorcio', 'pensão socio afetiva...         654  ...   \n",
              "11                                                  []       20138  ...   \n",
              "335                                                 []         119  ...   \n",
              "425                                                 []         358  ...   \n",
              "228  ['red pill', 'divorcio', 'pensão socio afetiva...        2718  ...   \n",
              "\n",
              "     concurrent_viewers  active_live_chat_id recording_date  \\\n",
              "310                   0                  NaN            NaN   \n",
              "11                    0                  NaN            NaN   \n",
              "335                   0                  NaN            NaN   \n",
              "425                   0                  NaN            NaN   \n",
              "228                   0                  NaN            NaN   \n",
              "\n",
              "                                       topicCategories  processing_status  \\\n",
              "310           ['https://en.wikipedia.org/wiki/Humour']                NaN   \n",
              "11           ['https://en.wikipedia.org/wiki/Society']                NaN   \n",
              "335                                                 []                NaN   \n",
              "425  ['https://en.wikipedia.org/wiki/Lifestyle_(soc...                NaN   \n",
              "228  ['https://en.wikipedia.org/wiki/Humour', 'http...                NaN   \n",
              "\n",
              "     parts_total parts_processed time_left_ms  processing_failure_reason  \\\n",
              "310            0               0            0                        NaN   \n",
              "11             0               0            0                        NaN   \n",
              "335            0               0            0                        NaN   \n",
              "425            0               0            0                        NaN   \n",
              "228            0               0            0                        NaN   \n",
              "\n",
              "                                                  text  \n",
              "310  mulher dizendo que não é normal homem mais vel...  \n",
              "11   esses homens estão preferindo solitude e não é...  \n",
              "335  gritos reclamações e raiva caminho mais rápido...  \n",
              "425  se encontrou um homem de valor valorize aprend...  \n",
              "228  mulher diz que paga marido para ter relação co...  \n",
              "\n",
              "[5 rows x 38 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentences = df['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-15 11:37:36,349 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:37:36,350 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Will be calculated...\n",
            "Failed to load variable from results_2025_06_10/topics_bertopic_2025_06_10.pkl: [Errno 2] No such file or directory: 'results_2025_06_10/topics_bertopic_2025_06_10.pkl'\n",
            "Topics will be calculated...\n",
            "Failed to load variable from results_2025_06_10/probs_bertopic_2025_06_10.pkl: [Errno 2] No such file or directory: 'results_2025_06_10/probs_bertopic_2025_06_10.pkl'\n",
            "Probs will be calculated...\n",
            "Melhores parâmetros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': {'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.5}, 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "Melhor coerência: 0.5921175102080011\n",
            "Getting embedding model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-15 11:37:38,486 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:37:38,487 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:37:40,740 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:37:40,742 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting reduction model...\n",
            "Getting clustering model...\n",
            "Getting TFIDF model...\n",
            "Getting representation model...\n",
            "Initializing model...\n",
            "Fitting model...\n",
            "Fitted\n"
          ]
        }
      ],
      "source": [
        "import ast  # Substituir eval por ast.literal_eval para maior segurança\n",
        "from utils.save_models_and_variables import load_model, load_variable\n",
        "try:\n",
        "    topic_model = load_model(f'{results_folder}/bertopic_{result_index}')\n",
        "    print(\"Previously calculated\" if topic_model else \"Will be calculated...\")\n",
        "\n",
        "    topics = load_variable(f'{results_folder}/topics_bertopic_{result_index}')\n",
        "    print(\"Topics previously calculated\" if topics else \"Topics will be calculated...\")\n",
        "\n",
        "    probs = load_variable(f'{results_folder}/probs_bertopic_{result_index}')\n",
        "    print(\"Probs previously calculated\" if probs is not None else \"Probs will be calculated...\")\n",
        "except:\n",
        "    topic_model = None\n",
        "    topics = None\n",
        "    probs = None\n",
        "\n",
        "if topic_model is None or probs is None or topics is None:\n",
        "    # sentences = unified_df[\"text\"]\n",
        "    \n",
        "    # Passo 2: Validar colunas no DataFrame\n",
        "    expected_columns = [\n",
        "        \"embedding_model\",\n",
        "        \"reduction_model\",\n",
        "        \"umap_params\",\n",
        "        \"clustering_model\",\n",
        "        \"representation_model\",\n",
        "        \"coherence\"  # Deve existir como métrica para identificar os melhores parâmetros\n",
        "    ]\n",
        "\n",
        "    missing_columns = [col for col in expected_columns if col not in results_df.columns]\n",
        "    if missing_columns:\n",
        "        raise ValueError(f\"As colunas seguintes estão faltando no results_df: {missing_columns}\")\n",
        "\n",
        "    # Passo 3: Identificar os melhores parâmetros\n",
        "    best_row = results_df.loc[results_df['coherence'].idxmax()]\n",
        "\n",
        "    # Garantir que umap_params seja convertido corretamente\n",
        "    try:\n",
        "        best_umap_params = ast.literal_eval(best_row['umap_params'])\n",
        "    except (ValueError, SyntaxError) as e:\n",
        "        raise ValueError(f\"Erro ao converter umap_params: {best_row['umap_params']}\") from e\n",
        "\n",
        "    # Extrair os melhores parâmetros\n",
        "    best_params = {\n",
        "        \"embedding_model\": best_row['embedding_model'],\n",
        "        \"reduction_model\": best_row[\"reduction_model\"],\n",
        "        \"umap_params\": best_umap_params,\n",
        "        \"clustering_model\": best_row['clustering_model'],\n",
        "        \"representation_model\": best_row[\"representation_model\"],\n",
        "    }\n",
        "    best_coherence = best_row[\"coherence\"]\n",
        "\n",
        "    print(\"Melhores parâmetros:\", best_params)\n",
        "    print(\"Melhor coerência:\", best_coherence)\n",
        "\n",
        "    # Continuar o restante do fluxo\n",
        "    print(\"Getting embedding model...\")\n",
        "    embedding_model = get_embedding_model(best_params[\"embedding_model\"])\n",
        "\n",
        "    print(\"Getting reduction model...\")\n",
        "    reduction_model = get_reduction_model(best_params[\"reduction_model\"], best_params[\"umap_params\"])\n",
        "\n",
        "    print(\"Getting clustering model...\")\n",
        "    clustering_model = get_clustering_model(best_params[\"clustering_model\"], 30)\n",
        "\n",
        "    print(\"Getting TFIDF model...\")\n",
        "    tfidf_vectorizer = TfidfVectorizer(stop_words='english', smooth_idf=True)\n",
        "\n",
        "    print(\"Getting representation model...\")\n",
        "    representation_model = get_representation_model(best_params[\"representation_model\"], None)\n",
        "    \n",
        "    print(\"Initializing model...\")\n",
        "    if topic_model is None:\n",
        "        topic_model = BERTopic(\n",
        "            language=\"portuguese\",\n",
        "            umap_model=reduction_model,\n",
        "            hdbscan_model=clustering_model,\n",
        "            vectorizer_model=tfidf_vectorizer,\n",
        "            representation_model=representation_model,\n",
        "            embedding_model=embedding_model,\n",
        "            min_topic_size=100,\n",
        "            nr_topics=5\n",
        "        )\n",
        "        \n",
        "    print(\"Fitting model...\")\n",
        "    topics, probs = topic_model.fit_transform(sentences)\n",
        "    print(\"Fitted\")\n",
        "    \n",
        "    try:\n",
        "        df[\"topic_id\"] = topics\n",
        "    except:\n",
        "        topic_mapping = dict(zip(sentences, topics))\n",
        "\n",
        "        # 🔹 4️⃣ Adicionar os tópicos ao DataFrame\n",
        "        df['topic'] = df['text'].map(topic_mapping)\n",
        "else:\n",
        "    df = pd.read_csv(f\"{results_folder}/topic_data.csv\")\n",
        "    print(\"Topic data previously calculated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No outliers to reduce.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Certifique-se de que o modelo está treinado antes de reduzir os outliers\n",
        "    if not hasattr(topic_model, \"topic_sizes_\"):  # Verifica se já foi treinado\n",
        "        topic_model.fit(sentences)  # Treina o modelo com as frases\n",
        "\n",
        "    # Reduzindo outliers\n",
        "    new_topics = topic_model.reduce_outliers(sentences, topics, strategy='c-tf-idf', threshold=0.05)\n",
        "\n",
        "    # Criando o vetorizador TF-IDF (caso não tenha sido definido antes)\n",
        "    vectorizer_model = TfidfVectorizer(stop_words='portuguese', smooth_idf=True)\n",
        "\n",
        "    # Atualizando o modelo com os novos tópicos\n",
        "    topic_model.update_topics(sentences, topics=new_topics, vectorizer_model=vectorizer_model)\n",
        "\n",
        "    # Exibindo informações sobre os tópicos\n",
        "    print(topic_model.get_topic_info())\n",
        "    print(\"Outliers reduced\")\n",
        "except ValueError:\n",
        "    print(\"No outliers to reduce.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-15 12:01:33,883 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 12:01:33,912 - INFO - built Dictionary<3981 unique tokens: ['###', '#conquistafeminina', '#mensagensdebomdia', '#psicologiamasculina', '#redpillfeminina']...> from 447 documents (total 52301 corpus positions)\n",
            "2025-06-15 12:01:33,912 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<3981 unique tokens: ['###', '#conquistafeminina', '#mensagensdebomdia', '#psicologiamasculina', '#redpillfeminina']...> from 447 documents (total 52301 corpus positions)\", 'datetime': '2025-06-15T12:01:33.912759', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 12:01:33,914 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 12:01:44,879 - INFO - 1 batches submitted to accumulate stats from 64 documents (651 virtual)\n",
            "2025-06-15 12:01:44,881 - INFO - 2 batches submitted to accumulate stats from 128 documents (1645 virtual)\n",
            "2025-06-15 12:01:44,883 - INFO - 3 batches submitted to accumulate stats from 192 documents (2157 virtual)\n",
            "2025-06-15 12:01:44,884 - INFO - 4 batches submitted to accumulate stats from 256 documents (2576 virtual)\n",
            "2025-06-15 12:01:44,885 - INFO - 5 batches submitted to accumulate stats from 320 documents (3553 virtual)\n",
            "2025-06-15 12:01:44,888 - INFO - 7 batches submitted to accumulate stats from 448 documents (3578 virtual)\n",
            "2025-06-15 12:01:45,062 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 12:01:45,070 - INFO - accumulated word occurrence stats for 19259 virtual documents\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Esse modelo tem coerência de 0.8459217505426448\n"
          ]
        }
      ],
      "source": [
        "coherence_score = calculate_coherence(topic_model, sentences)\n",
        "\n",
        "print(f\"Esse modelo tem coerência de {coherence_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'evitar_feito_antiotário_ser_redpillbrasil',\n",
              " 1: 'memes_vindo_humor_canal_não',\n",
              " 2: 'capítulo_como_homem_ele_emocional',\n",
              " 3: 'http_redcast_master_junior_instagram',\n",
              " 4: 'http_conselho_projetoconselhosubstackcom_comercial_recomendo',\n",
              " -1: 'outlier'}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dicionário para armazenar os nomes dos tópicos\n",
        "topic_names_dict = {}\n",
        "\n",
        "# Obter informações dos tópicos\n",
        "topics = topic_model.get_topic_info()\n",
        "\n",
        "# Gerar títulos para os tópicos\n",
        "for topic_id in topics['Topic']:\n",
        "    top_words = [word for word, _ in topic_model.get_topic(topic_id)[:5]]\n",
        "    topic_name = \"_\".join(top_words)\n",
        "    topic_names_dict[topic_id] = topic_name\n",
        "    \n",
        "topic_names_dict[-1] = 'outlier'\n",
        "\n",
        "# Exibir o dicionário resultante\n",
        "topic_names_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6 topicos gerados\n"
          ]
        }
      ],
      "source": [
        "print(f\"{len(topic_names_dict)} topicos gerados\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "447 antes do filtro\n",
            "447 depois do filtro\n"
          ]
        }
      ],
      "source": [
        "print(f\"{len(df)} antes do filtro\")\n",
        "df = df.drop_duplicates(subset=[ \"video_id\"])\n",
        "df = df.dropna(subset=[\"video_id\"])\n",
        "print(f\"{len(df)} depois do filtro\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🔹 4️⃣ Comparação dentro de cada caso   \n",
        "def print_topic(case):\n",
        "    case_df = df[df[\"case\"] == case]\n",
        "    \n",
        "    print(f\"\\n🔹 Comparação de tópicos para o caso: {case}\")\n",
        "    \n",
        "    # Verificar quando o mesmo autor tem um tópico diferente para vídeo e notícia\n",
        "    differing_topics = case_df[case_df[\"news_topic\"] != case_df[\"video_topic\"]]\n",
        "    \n",
        "    print(f\"Número de diferenças entre tópicos no caso {case}: {len(differing_topics)}\")\n",
        "\n",
        "    # Se quiser ver exemplos específicos de diferenças:\n",
        "    return differing_topics[['news_author', 'video_author', 'news_topic', 'video_topic', 'news_title', 'video_title', 'news_text', 'video_text']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exportação de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved model: results_2025_06_10/bertopic.pkl\n",
            "Saved variable: results_2025_06_10/topics_bertopic.pkl\n",
            "Saved variable: results_2025_06_10/probs_bertopic.pkl\n",
            "Saved variable: results_2025_06_10/topics_dict.pkl\n"
          ]
        }
      ],
      "source": [
        "from utils.save_models_and_variables import save_model, save_variable\n",
        "\n",
        "save_model(topic_model, f'{results_folder}/bertopic')\n",
        "save_variable(topics, f'{results_folder}/topics_bertopic')\n",
        "save_variable(probs, f'{results_folder}/probs_bertopic')\n",
        "save_variable(topic_names_dict, f'{results_folder}/topics_dict')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "fWYMqE0xYpOz"
      },
      "outputs": [],
      "source": [
        "df.to_csv(f'{results_folder}/topic_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "447"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
