{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRQaYx9PYpOm"
      },
      "source": [
        "## ConfiguraÃ§Ã£o de Ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from config import result_index\n",
        "\n",
        "results_folder = f\"results_{result_index}\"\n",
        "results_file = f\"{results_folder}/finetuning_results.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCwYm-vtYpOq",
        "outputId": "ff0187e4-afbf-4a23-fcf3-2bf9ddd3f6f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.10.3)\n",
            "Requirement already satisfied: bertopic in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.17.0)\n",
            "Requirement already satisfied: plotly in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (6.1.2)\n",
            "Requirement already satisfied: datamapplot in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.6.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: hdbscan>=0.8.29 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bertopic) (0.8.40)\n",
            "Requirement already satisfied: pandas>=1.1.5 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bertopic) (2.2.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bertopic) (1.6.1)\n",
            "Requirement already satisfied: sentence-transformers>=0.4.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bertopic) (4.1.0)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bertopic) (4.67.1)\n",
            "Requirement already satisfied: umap-learn>=0.5.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bertopic) (0.5.7)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from plotly) (1.42.1)\n",
            "Requirement already satisfied: colorcet in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (3.1.0)\n",
            "Requirement already satisfied: colorspacious>=1.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (1.1.2)\n",
            "Requirement already satisfied: dask<2025.0.1,>=2024.4.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (2024.12.1)\n",
            "Requirement already satisfied: datashader>=0.16 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (6.5.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (3.1.6)\n",
            "Requirement already satisfied: numba>=0.56 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (0.61.2)\n",
            "Requirement already satisfied: pyarrow in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (20.0.0)\n",
            "Requirement already satisfied: pylabeladjust in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (0.1.13)\n",
            "Requirement already satisfied: requests in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (2.32.3)\n",
            "Requirement already satisfied: rcssmin>=1.1.2 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (1.2.1)\n",
            "Requirement already satisfied: rjsmin>=1.2.2 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (1.2.4)\n",
            "Requirement already satisfied: scikit-image>=0.22 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (0.25.2)\n",
            "Requirement already satisfied: platformdirs in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (4.3.7)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datamapplot) (4.13.2)\n",
            "Requirement already satisfied: click>=8.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (3.1.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (2024.12.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (1.0.0)\n",
            "Requirement already satisfied: importlib_metadata>=4.13.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (8.7.0)\n",
            "Requirement already satisfied: lz4>=4.3.2 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (4.4.4)\n",
            "Requirement already satisfied: multipledispatch in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datashader>=0.16->datamapplot) (1.0.0)\n",
            "Requirement already satisfied: param in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datashader>=0.16->datamapplot) (2.2.1)\n",
            "Requirement already satisfied: pyct in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datashader>=0.16->datamapplot) (0.5.0)\n",
            "Requirement already satisfied: scipy in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datashader>=0.16->datamapplot) (1.13.1)\n",
            "Requirement already satisfied: xarray in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datashader>=0.16->datamapplot) (2025.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from hdbscan>=0.8.29->bertopic) (1.4.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from numba>=0.56->datamapplot) (0.44.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.1.5->bertopic) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.1.5->bertopic) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: networkx>=3.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-image>=0.22->datamapplot) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-image>=0.22->datamapplot) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-image>=0.22->datamapplot) (2025.6.11)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-image>=0.22->datamapplot) (0.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn>=1.0->bertopic) (3.6.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers>=0.4.1->bertopic) (4.51.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers>=0.4.1->bertopic) (2.7.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers>=0.4.1->bertopic) (0.30.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.41.1->bertopic) (0.4.6)\n",
            "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from umap-learn>=0.5.0->bertopic) (0.5.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->datamapplot) (3.0.2)\n",
            "Requirement already satisfied: Pyqtree<2.0.0,>=1.0.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pylabeladjust->datamapplot) (1.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->datamapplot) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->datamapplot) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->datamapplot) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->datamapplot) (2025.4.26)\n",
            "Requirement already satisfied: filelock in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.18.0)\n",
            "Requirement already satisfied: zipp>=3.20 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from importlib_metadata>=4.13.0->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (3.21.0)\n",
            "Requirement already satisfied: locket in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from partd>=1.4.0->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (1.0.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.14.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.5.3)\n",
            "Requirement already satisfied: dask-expr<1.2,>=1.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (1.1.21)\n",
            "Requirement already satisfied: distributed==2024.12.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (2024.12.1)\n",
            "Requirement already satisfied: bokeh>=3.1.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (3.7.3)\n",
            "Requirement already satisfied: msgpack>=1.0.2 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from distributed==2024.12.1->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (1.1.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from distributed==2024.12.1->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (7.0.0)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from distributed==2024.12.1->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from distributed==2024.12.1->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (3.1.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from distributed==2024.12.1->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (6.4.2)\n",
            "Requirement already satisfied: zict>=3.0.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from distributed==2024.12.1->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (3.0.0)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from bokeh>=3.1.0->dask<2025.0.1,>=2024.4.1->dask[complete]<2025.0.1,>=2024.4.1->datamapplot) (2025.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
            "[notice] To update, run: C:\\Users\\vmart\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.84.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (2.11.3)\n",
            "Requirement already satisfied: sniffio in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
            "[notice] To update, run: C:\\Users\\vmart\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.51.3)\n",
            "Requirement already satisfied: sympy in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.14.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy) (1.3.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2025.4.26)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
            "[notice] To update, run: C:\\Users\\vmart\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wordcloud in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.9.4)\n",
            "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from wordcloud) (1.26.4)\n",
            "Requirement already satisfied: pillow in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from wordcloud) (11.2.1)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from wordcloud) (3.10.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
            "[notice] To update, run: C:\\Users\\vmart\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Usage:   \n",
            "  C:\\Users\\vmart\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install [options] <requirement specifier> [package-index-options] ...\n",
            "  C:\\Users\\vmart\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install [options] -r <requirements file> [package-index-options] ...\n",
            "  C:\\Users\\vmart\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install [options] [-e] <vcs project url> ...\n",
            "  C:\\Users\\vmart\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install [options] [-e] <local project path> ...\n",
            "  C:\\Users\\vmart\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -u\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.24.4\n",
            "  Downloading numpy-1.24.4-cp311-cp311-win_amd64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: gensim in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.3.3)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading numpy-1.24.4-cp311-cp311-win_amd64.whl (14.8 MB)\n",
            "   ---------------------------------------- 0.0/14.8 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/14.8 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/14.8 MB 653.6 kB/s eta 0:00:23\n",
            "    --------------------------------------- 0.3/14.8 MB 2.8 MB/s eta 0:00:06\n",
            "   ----- ---------------------------------- 2.0/14.8 MB 14.4 MB/s eta 0:00:01\n",
            "   ----------- ---------------------------- 4.3/14.8 MB 23.2 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 6.3/14.8 MB 27.1 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 7.9/14.8 MB 29.6 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 10.2/14.8 MB 32.8 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 13.0/14.8 MB 50.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  14.8/14.8 MB 46.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 14.8/14.8 MB 40.9 MB/s eta 0:00:00\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "Successfully installed numpy-1.24.4\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\vmart\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\~-mpy.libs'.\n",
            "  You can safely remove it manually.\n",
            "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\vmart\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\~-mpy'.\n",
            "  You can safely remove it manually.\n",
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
            "[notice] To update, run: C:\\Users\\vmart\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade matplotlib bertopic plotly datamapplot\n",
        "%pip install openai\n",
        "%pip install transformers sympy\n",
        "%pip install wordcloud\n",
        "%pip install -u kaleido\n",
        "%pip install numpy==1.24.4 gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ecvfqx4D3NNc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\vmart\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from gensim.corpora import Dictionary\n",
        "\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "import logging\n",
        "from itertools import product\n",
        "\n",
        "from bertopic import BERTopic\n",
        "from bertopic.representation import MaximalMarginalRelevance, KeyBERTInspired, OpenAI\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
        "\n",
        "from hdbscan import HDBSCAN\n",
        "import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKMwXSj4YpOu"
      },
      "source": [
        "## ImportaÃ§Ã£o de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AJSGkZCOZKcy"
      },
      "outputs": [],
      "source": [
        "# Substitua pelo caminho correto\n",
        "file_path = f'processed_data_{result_index}/cleaned_videos.csv'\n",
        "\n",
        "df = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>video_id</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>channel_id</th>\n",
              "      <th>published_at</th>\n",
              "      <th>category_id</th>\n",
              "      <th>tags</th>\n",
              "      <th>view_count</th>\n",
              "      <th>...</th>\n",
              "      <th>concurrent_viewers</th>\n",
              "      <th>active_live_chat_id</th>\n",
              "      <th>recording_date</th>\n",
              "      <th>topicCategories</th>\n",
              "      <th>processing_status</th>\n",
              "      <th>parts_total</th>\n",
              "      <th>parts_processed</th>\n",
              "      <th>time_left_ms</th>\n",
              "      <th>processing_failure_reason</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>264</td>\n",
              "      <td>294.0</td>\n",
              "      <td>nO06xfLips8</td>\n",
              "      <td>MÃ£e sensata? Ã‰ Ã³timo! Mas homem que sÃ³ amadure...</td>\n",
              "      <td>#rafaelaires #antiotario #redpillbrasil\\n\\nðŸ”¥ P...</td>\n",
              "      <td>UCAYoI16-UkXemcnhC-kTvDQ</td>\n",
              "      <td>2025-05-12 21:00:54</td>\n",
              "      <td>22</td>\n",
              "      <td>[]</td>\n",
              "      <td>113</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://en.wikipedia.org/wiki/Society']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>mÃ£e sensata Ã© Ã³timo ma homem que sÃ³ amadurece ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>832</td>\n",
              "      <td>NaN</td>\n",
              "      <td>wUQwbUKrzME</td>\n",
              "      <td>NÃ£o seja o cara que implora! Mulher admira cor...</td>\n",
              "      <td>#rafaelaires #antiotario #redpillbrasil\\n\\nðŸ”¥ P...</td>\n",
              "      <td>UCAYoI16-UkXemcnhC-kTvDQ</td>\n",
              "      <td>2025-05-06 21:01:05</td>\n",
              "      <td>22</td>\n",
              "      <td>[]</td>\n",
              "      <td>129</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://en.wikipedia.org/wiki/Lifestyle_(soc...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>nÃ£o seja cara que implora mulher admira corage...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>228</td>\n",
              "      <td>255.0</td>\n",
              "      <td>w7tH6YIZyqc</td>\n",
              "      <td>MULHER DIZ QUE PAGA MARIDO PARA TER RELAÃ‡ÃƒO CO...</td>\n",
              "      <td>OlÃ¡! seja bem vindo a mais um video do canal, ...</td>\n",
              "      <td>UCRmNflJuD1TxLbRlDV08_7g</td>\n",
              "      <td>2025-05-15 01:55:09</td>\n",
              "      <td>24</td>\n",
              "      <td>['red pill', 'divorcio', 'pensÃ£o socio afetiva...</td>\n",
              "      <td>2718</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://en.wikipedia.org/wiki/Humour', 'http...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>mulher diz que paga marido para ter relaÃ§Ã£o co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>21.0</td>\n",
              "      <td>2YhQqPj6aSQ</td>\n",
              "      <td>Homem feio tem mais chance de ser fiel? | Qual...</td>\n",
              "      <td>#rafaelaires #antiotario #redpillbrasil\\n\\nðŸ”¥ P...</td>\n",
              "      <td>UCAYoI16-UkXemcnhC-kTvDQ</td>\n",
              "      <td>2025-05-29 21:00:02</td>\n",
              "      <td>22</td>\n",
              "      <td>[]</td>\n",
              "      <td>708951</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>homem feio tem mais chance de ser fiel qual su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>794</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fdz39IZljTg</td>\n",
              "      <td>COROA CONTA QUE CONHECEU UM NOVINHO NUMA REDE ...</td>\n",
              "      <td>seja bem vindo a mais um vÃ­deo do canal NÃ£o se...</td>\n",
              "      <td>UCUBeVY6Kn7ulBmUGynJqISw</td>\n",
              "      <td>2025-05-09 02:19:06</td>\n",
              "      <td>24</td>\n",
              "      <td>['redpill', 'msol', 'miqueinha', 'relacionamen...</td>\n",
              "      <td>1148</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://en.wikipedia.org/wiki/Humour', 'http...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>coroa conta que conheceu um novinho numa rede ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 38 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0.1  Unnamed: 0     video_id  \\\n",
              "264           264       294.0  nO06xfLips8   \n",
              "349           832         NaN  wUQwbUKrzME   \n",
              "228           228       255.0  w7tH6YIZyqc   \n",
              "20             20        21.0  2YhQqPj6aSQ   \n",
              "314           794         NaN  Fdz39IZljTg   \n",
              "\n",
              "                                                 title  \\\n",
              "264  MÃ£e sensata? Ã‰ Ã³timo! Mas homem que sÃ³ amadure...   \n",
              "349  NÃ£o seja o cara que implora! Mulher admira cor...   \n",
              "228  MULHER DIZ QUE PAGA MARIDO PARA TER RELAÃ‡ÃƒO CO...   \n",
              "20   Homem feio tem mais chance de ser fiel? | Qual...   \n",
              "314  COROA CONTA QUE CONHECEU UM NOVINHO NUMA REDE ...   \n",
              "\n",
              "                                           description  \\\n",
              "264  #rafaelaires #antiotario #redpillbrasil\\n\\nðŸ”¥ P...   \n",
              "349  #rafaelaires #antiotario #redpillbrasil\\n\\nðŸ”¥ P...   \n",
              "228  OlÃ¡! seja bem vindo a mais um video do canal, ...   \n",
              "20   #rafaelaires #antiotario #redpillbrasil\\n\\nðŸ”¥ P...   \n",
              "314  seja bem vindo a mais um vÃ­deo do canal NÃ£o se...   \n",
              "\n",
              "                   channel_id         published_at  category_id  \\\n",
              "264  UCAYoI16-UkXemcnhC-kTvDQ  2025-05-12 21:00:54           22   \n",
              "349  UCAYoI16-UkXemcnhC-kTvDQ  2025-05-06 21:01:05           22   \n",
              "228  UCRmNflJuD1TxLbRlDV08_7g  2025-05-15 01:55:09           24   \n",
              "20   UCAYoI16-UkXemcnhC-kTvDQ  2025-05-29 21:00:02           22   \n",
              "314  UCUBeVY6Kn7ulBmUGynJqISw  2025-05-09 02:19:06           24   \n",
              "\n",
              "                                                  tags  view_count  ...  \\\n",
              "264                                                 []         113  ...   \n",
              "349                                                 []         129  ...   \n",
              "228  ['red pill', 'divorcio', 'pensÃ£o socio afetiva...        2718  ...   \n",
              "20                                                  []      708951  ...   \n",
              "314  ['redpill', 'msol', 'miqueinha', 'relacionamen...        1148  ...   \n",
              "\n",
              "     concurrent_viewers  active_live_chat_id recording_date  \\\n",
              "264                   0                  NaN            NaN   \n",
              "349                   0                  NaN            NaN   \n",
              "228                   0                  NaN            NaN   \n",
              "20                    0                  NaN            NaN   \n",
              "314                   0                  NaN            NaN   \n",
              "\n",
              "                                       topicCategories  processing_status  \\\n",
              "264          ['https://en.wikipedia.org/wiki/Society']                NaN   \n",
              "349  ['https://en.wikipedia.org/wiki/Lifestyle_(soc...                NaN   \n",
              "228  ['https://en.wikipedia.org/wiki/Humour', 'http...                NaN   \n",
              "20                                                  []                NaN   \n",
              "314  ['https://en.wikipedia.org/wiki/Humour', 'http...                NaN   \n",
              "\n",
              "     parts_total parts_processed time_left_ms  processing_failure_reason  \\\n",
              "264            0               0            0                        NaN   \n",
              "349            0               0            0                        NaN   \n",
              "228            0               0            0                        NaN   \n",
              "20             0               0            0                        NaN   \n",
              "314            0               0            0                        NaN   \n",
              "\n",
              "                                                  text  \n",
              "264  mÃ£e sensata Ã© Ã³timo ma homem que sÃ³ amadurece ...  \n",
              "349  nÃ£o seja cara que implora mulher admira corage...  \n",
              "228  mulher diz que paga marido para ter relaÃ§Ã£o co...  \n",
              "20   homem feio tem mais chance de ser fiel qual su...  \n",
              "314  coroa conta que conheceu um novinho numa rede ...  \n",
              "\n",
              "[5 rows x 38 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "447  textos\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0.1', 'Unnamed: 0', 'video_id', 'title', 'description',\n",
              "       'channel_id', 'published_at', 'category_id', 'tags', 'view_count',\n",
              "       'like_count', 'comment_count', 'duration', 'definition', 'caption',\n",
              "       'licensed_content', 'privacy_status', 'license', 'embeddable',\n",
              "       'public_stats_viewable', 'is_made_for_kids', 'thumbnail_url',\n",
              "       'default_audio_language', 'default_language', 'actual_start_time',\n",
              "       'scheduled_start_time', 'actual_end_time', 'scheduled_end_time',\n",
              "       'concurrent_viewers', 'active_live_chat_id', 'recording_date',\n",
              "       'topicCategories', 'processing_status', 'parts_total',\n",
              "       'parts_processed', 'time_left_ms', 'processing_failure_reason', 'text'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(len(df), \" textos\")\n",
        "\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['UCO9FRrBUwGdYopkMbGGKbpg', 'UCAYoI16-UkXemcnhC-kTvDQ',\n",
              "       'UCRmNflJuD1TxLbRlDV08_7g', 'UCUBeVY6Kn7ulBmUGynJqISw',\n",
              "       'UCeL1a4rpEA8UG9IQIewPccg', 'UC3nQ4xUl6rodOWuQbBULyow',\n",
              "       'UCNiU1wZxK6YN-KuJP7QMpBQ', 'UCX0VSzJ2z5l0C9wnwh5SoRw',\n",
              "       'UCExFA9MsrRmWnXUlhiwu4qA'], dtype=object)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['channel_id'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_videos = df.sample(n=100, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = pd.concat([train_videos])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>video_id</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>channel_id</th>\n",
              "      <th>published_at</th>\n",
              "      <th>category_id</th>\n",
              "      <th>tags</th>\n",
              "      <th>view_count</th>\n",
              "      <th>...</th>\n",
              "      <th>concurrent_viewers</th>\n",
              "      <th>active_live_chat_id</th>\n",
              "      <th>recording_date</th>\n",
              "      <th>topicCategories</th>\n",
              "      <th>processing_status</th>\n",
              "      <th>parts_total</th>\n",
              "      <th>parts_processed</th>\n",
              "      <th>time_left_ms</th>\n",
              "      <th>processing_failure_reason</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>378</th>\n",
              "      <td>863</td>\n",
              "      <td>NaN</td>\n",
              "      <td>k_9RUZzvCwY</td>\n",
              "      <td>PRESAS DIZEM PARA AS NOVINHAS NÃƒO FAZER COISA ...</td>\n",
              "      <td>seja bem vindo a mais um vÃ­deo do canal NÃ£o se...</td>\n",
              "      <td>UCUBeVY6Kn7ulBmUGynJqISw</td>\n",
              "      <td>2025-05-05 11:19:45</td>\n",
              "      <td>24</td>\n",
              "      <td>['redpill', 'msol', 'miqueinha', 'relacionamen...</td>\n",
              "      <td>682</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://en.wikipedia.org/wiki/Lifestyle_(soc...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>presas dizem para novinhas nÃ£o fazer coisa err...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>75</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9U9Rq6_B5Ts</td>\n",
              "      <td>Sinais que ela vai te colocar na cadeia! | Qua...</td>\n",
              "      <td>#rafaelaires #antiotario #redpillbrasil\\n\\nðŸ”¥ P...</td>\n",
              "      <td>UCAYoI16-UkXemcnhC-kTvDQ</td>\n",
              "      <td>2025-05-26 15:00:25</td>\n",
              "      <td>22</td>\n",
              "      <td>[]</td>\n",
              "      <td>37994</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://en.wikipedia.org/wiki/Health']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>sinai que ela vai te colocar na cadeia qual su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>79</td>\n",
              "      <td>84.0</td>\n",
              "      <td>7qkwWygX8y8</td>\n",
              "      <td>A mulher que nÃ£o Ã© submissa ao marido estÃ¡ fad...</td>\n",
              "      <td>#rafaelaires #antiotario #redpillbrasil\\n\\nðŸ”¥ P...</td>\n",
              "      <td>UCAYoI16-UkXemcnhC-kTvDQ</td>\n",
              "      <td>2025-05-26 12:00:13</td>\n",
              "      <td>22</td>\n",
              "      <td>[]</td>\n",
              "      <td>75205</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>mulher que nÃ£o Ã© submissa ao marido estÃ¡ fadad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>537</td>\n",
              "      <td>NaN</td>\n",
              "      <td>lRscpUdKfVU</td>\n",
              "      <td>Rapaz leva flores e amiga da namorada debocha....</td>\n",
              "      <td>#rafaelaires #antiotario #redpillbrasil\\n\\nðŸ”¥ P...</td>\n",
              "      <td>UCAYoI16-UkXemcnhC-kTvDQ</td>\n",
              "      <td>2025-05-25 15:01:12</td>\n",
              "      <td>22</td>\n",
              "      <td>[]</td>\n",
              "      <td>8802</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://en.wikipedia.org/wiki/Society']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>rapaz lev flores e amiga da namorada debocha q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>517</td>\n",
              "      <td>NaN</td>\n",
              "      <td>GjYlzOd82Qc</td>\n",
              "      <td>MULHER GRAVANDO PARA PROVAR QUE NÃƒO PRECISA DE...</td>\n",
              "      <td>OlÃ¡! seja bem vindo a mais um video do canal, ...</td>\n",
              "      <td>UCRmNflJuD1TxLbRlDV08_7g</td>\n",
              "      <td>2025-05-27 02:01:00</td>\n",
              "      <td>24</td>\n",
              "      <td>['red pill', 'divorcio', 'pensÃ£o socio afetiva...</td>\n",
              "      <td>255</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://en.wikipedia.org/wiki/Entertainment'...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>mulher gravando para provar que nÃ£o precisa de...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 38 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0.1  Unnamed: 0     video_id  \\\n",
              "378           863         NaN  k_9RUZzvCwY   \n",
              "75             75        80.0  9U9Rq6_B5Ts   \n",
              "79             79        84.0  7qkwWygX8y8   \n",
              "84            537         NaN  lRscpUdKfVU   \n",
              "66            517         NaN  GjYlzOd82Qc   \n",
              "\n",
              "                                                 title  \\\n",
              "378  PRESAS DIZEM PARA AS NOVINHAS NÃƒO FAZER COISA ...   \n",
              "75   Sinais que ela vai te colocar na cadeia! | Qua...   \n",
              "79   A mulher que nÃ£o Ã© submissa ao marido estÃ¡ fad...   \n",
              "84   Rapaz leva flores e amiga da namorada debocha....   \n",
              "66   MULHER GRAVANDO PARA PROVAR QUE NÃƒO PRECISA DE...   \n",
              "\n",
              "                                           description  \\\n",
              "378  seja bem vindo a mais um vÃ­deo do canal NÃ£o se...   \n",
              "75   #rafaelaires #antiotario #redpillbrasil\\n\\nðŸ”¥ P...   \n",
              "79   #rafaelaires #antiotario #redpillbrasil\\n\\nðŸ”¥ P...   \n",
              "84   #rafaelaires #antiotario #redpillbrasil\\n\\nðŸ”¥ P...   \n",
              "66   OlÃ¡! seja bem vindo a mais um video do canal, ...   \n",
              "\n",
              "                   channel_id         published_at  category_id  \\\n",
              "378  UCUBeVY6Kn7ulBmUGynJqISw  2025-05-05 11:19:45           24   \n",
              "75   UCAYoI16-UkXemcnhC-kTvDQ  2025-05-26 15:00:25           22   \n",
              "79   UCAYoI16-UkXemcnhC-kTvDQ  2025-05-26 12:00:13           22   \n",
              "84   UCAYoI16-UkXemcnhC-kTvDQ  2025-05-25 15:01:12           22   \n",
              "66   UCRmNflJuD1TxLbRlDV08_7g  2025-05-27 02:01:00           24   \n",
              "\n",
              "                                                  tags  view_count  ...  \\\n",
              "378  ['redpill', 'msol', 'miqueinha', 'relacionamen...         682  ...   \n",
              "75                                                  []       37994  ...   \n",
              "79                                                  []       75205  ...   \n",
              "84                                                  []        8802  ...   \n",
              "66   ['red pill', 'divorcio', 'pensÃ£o socio afetiva...         255  ...   \n",
              "\n",
              "     concurrent_viewers  active_live_chat_id recording_date  \\\n",
              "378                   0                  NaN            NaN   \n",
              "75                    0                  NaN            NaN   \n",
              "79                    0                  NaN            NaN   \n",
              "84                    0                  NaN            NaN   \n",
              "66                    0                  NaN            NaN   \n",
              "\n",
              "                                       topicCategories  processing_status  \\\n",
              "378  ['https://en.wikipedia.org/wiki/Lifestyle_(soc...                NaN   \n",
              "75            ['https://en.wikipedia.org/wiki/Health']                NaN   \n",
              "79                                                  []                NaN   \n",
              "84           ['https://en.wikipedia.org/wiki/Society']                NaN   \n",
              "66   ['https://en.wikipedia.org/wiki/Entertainment'...                NaN   \n",
              "\n",
              "     parts_total parts_processed time_left_ms  processing_failure_reason  \\\n",
              "378            0               0            0                        NaN   \n",
              "75             0               0            0                        NaN   \n",
              "79             0               0            0                        NaN   \n",
              "84             0               0            0                        NaN   \n",
              "66             0               0            0                        NaN   \n",
              "\n",
              "                                                  text  \n",
              "378  presas dizem para novinhas nÃ£o fazer coisa err...  \n",
              "75   sinai que ela vai te colocar na cadeia qual su...  \n",
              "79   mulher que nÃ£o Ã© submissa ao marido estÃ¡ fadad...  \n",
              "84   rapaz lev flores e amiga da namorada debocha q...  \n",
              "66   mulher gravando para provar que nÃ£o precisa de...  \n",
              "\n",
              "[5 rows x 38 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "o5Rw8VbLYpOw"
      },
      "outputs": [],
      "source": [
        "# Remove textos vazios ou contendo apenas espaÃ§os em branco\n",
        "train_sentences = [text for text in train_data['text'].tolist() if isinstance(text, str) and text.strip()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ExecuÃ§Ã£o do Grid Search\n",
        "\n",
        "os hiperparÃ¢metros do modelo podem influenciar significativamente os resultados do modelo e uma escolha indevida poderia compremeter os resultados. Uma estratÃ©gia conhecida para evitar valores inadequados de hiperparÃ¢metros Ã© a Grid Search, que se trata de uma busca iterativa com parÃ¢metros prÃ©-selecionados. Os hiperparÃ¢metros testados e a coerÃªncia gerada a partir de suas combinaÃ§Ãµes estÃ£o visiveis na seÃ§Ã£o abaixo. A partir do melhor resultado encontrado a partir da busca extensiva, todos os dados foram integralmente submetidos a outra instÃ¢ncia do algoritmo, usando-se os hiperpÃ¢metros selecionados.\n",
        "\n",
        "Apesar de diversos hiperparÃ¢metros estarem sendo avaliados, destaco aqui os modelos de prÃ©-treino de embedding e o uso do TF-IDF para e UMAP para aprimorar e reduzir a dimensionalidade dos dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rNFzDlqiYpOv"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    \"embedding_model_name\": [\n",
        "        \"all-MiniLM-L6-v2\",\n",
        "        \"roberta\",\n",
        "        \"paraphrase-MiniLM-L6-v2\"\n",
        "    ],\n",
        "    \"reduction_model_name\": [\n",
        "        \"umap\"\n",
        "    ],\n",
        "    \"umap_params\": [\n",
        "        {\"n_neighbors\": 5, \"n_components\": 5, \"min_dist\": 0.1},\n",
        "        {\"n_neighbors\": 20, \"n_components\": 5, \"min_dist\": 0.1},\n",
        "        {\"n_neighbors\": 50, \"n_components\": 5, \"min_dist\": 0.1},\n",
        "        {\"n_neighbors\": 100, \"n_components\": 5, \"min_dist\": 0.1},\n",
        "        {\"n_neighbors\": 5, \"n_components\": 5, \"min_dist\": 0.5},\n",
        "        {\"n_neighbors\": 20, \"n_components\": 5, \"min_dist\": 0.5},\n",
        "        {\"n_neighbors\": 50, \"n_components\": 5, \"min_dist\": 0.5},\n",
        "        {\"n_neighbors\": 100, \"n_components\": 5, \"min_dist\": 0.5},\n",
        "    ],  # ParÃ¢metros para UMAP\n",
        "    \"clustering_model_name\": [\n",
        "        \"hdbscan\",\n",
        "        # \"agglomerative\",\n",
        "        \"kmeans\"\n",
        "    ],\n",
        "    \"representation_model_name\": [\n",
        "        \"maximal_marginal_relevance\"\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "eZ6fKVfDYpOw"
      },
      "outputs": [],
      "source": [
        "def get_embedding_model(name):\n",
        "    \"\"\"Retrieve embedding model based on name.\"\"\"\n",
        "    models = {\n",
        "        \"all-MiniLM-L6-v2\": SentenceTransformer('all-MiniLM-L6-v2'),\n",
        "        \"roberta\": SentenceTransformer('roberta-base-nli-stsb-mean-tokens'),\n",
        "        \"paraphrase-MiniLM-L6-v2\": SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "    }\n",
        "    return models.get(name, None)\n",
        "\n",
        "def get_reduction_model(reduction_model_name, umap_params=None):\n",
        "    \"\"\"\n",
        "    FunÃ§Ã£o para retornar o modelo de reduÃ§Ã£o de dimensionalidade baseado no nome.\n",
        "    \"\"\"\n",
        "    if reduction_model_name == \"umap\":\n",
        "        import umap\n",
        "        return umap.UMAP(\n",
        "            n_neighbors=umap_params.get(\"n_neighbors\", 15),\n",
        "            n_components=umap_params.get(\"n_components\", 2),\n",
        "            min_dist=umap_params.get(\"min_dist\", 0.1),\n",
        "            random_state=42,\n",
        "            low_memory=True\n",
        "        )\n",
        "    raise ValueError(f\"Reduction model '{reduction_model_name}' nÃ£o suportado.\")\n",
        "\n",
        "def get_clustering_model(name, min_cluster_size):\n",
        "    \"\"\"Retrieve clustering model based on name.\"\"\"\n",
        "    if name == \"hdbscan\":\n",
        "        return HDBSCAN(min_cluster_size=min_cluster_size, prediction_data=True)\n",
        "    elif name == \"agglomerative\":\n",
        "        return AgglomerativeClustering(n_clusters=min_cluster_size)\n",
        "    elif name == \"kmeans\":\n",
        "        return KMeans(n_clusters=min_cluster_size, random_state=42)\n",
        "    return None\n",
        "\n",
        "def get_representation_model(name, diversity):\n",
        "    \"\"\"Retrieve representation model.\"\"\"\n",
        "    if name == \"mmr\":\n",
        "        return MaximalMarginalRelevance(diversity=diversity)\n",
        "    elif name == \"keybert\":\n",
        "        return KeyBERTInspired(diversity=diversity)\n",
        "    elif name == \"openai\":\n",
        "        from config import OPENAI_KEY\n",
        "        client = openai.OpenAI(api_key=OPENAI_KEY)\n",
        "        return OpenAI(client, model=\"gpt-3.5-turbo\", chat=True)\n",
        "    return None\n",
        "\n",
        "def calculate_coherence(topic_model, sentences):\n",
        "    \"\"\"Calculate coherence score for a BERTopic model.\"\"\"\n",
        "    texts = [sentence.split() for sentence in sentences]\n",
        "    dictionary = Dictionary(texts)\n",
        "    topic_ids = topic_model.get_topics().keys()\n",
        "    topics = [[word for word, _ in topic_model.get_topics()[topic_id]] for topic_id in topic_ids]\n",
        "    coherence_model = CoherenceModel(\n",
        "        topics=topics,\n",
        "        texts=texts,\n",
        "        dictionary=dictionary,\n",
        "        coherence=\"c_v\"\n",
        "    )\n",
        "    return coherence_model.get_coherence()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8AkqRvk1YpOw"
      },
      "outputs": [],
      "source": [
        "# ConfiguraÃ§Ã£o de logging\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "\n",
        "def perform_grid_search(sentences, param_grid, results_file):\n",
        "    \"\"\"\n",
        "    Realiza busca em grade para hiperparÃ¢metros de BERTopic ou utiliza os melhores parÃ¢metros salvos.\n",
        "    \"\"\"\n",
        "    best_coherence = -np.inf\n",
        "\n",
        "    # Calcula todas as combinaÃ§Ãµes de parÃ¢metros\n",
        "    all_combinations = list(product(*param_grid.values()))\n",
        "    total_combinations = len(all_combinations)\n",
        "\n",
        "    try:\n",
        "        results_df = pd.read_csv(results_file)\n",
        "        if not results_df.empty:\n",
        "            logging.info(\"\\n=== Alguns modelos jÃ¡ foram previamente calculados ===\")\n",
        "\n",
        "            # Verifica se todas as combinaÃ§Ãµes jÃ¡ foram calculadas\n",
        "            calculated_combinations = results_df[[\n",
        "                \"embedding_model\", \"reduction_model\", \"umap_params\",\n",
        "                \"clustering_model\", \"representation_model\"\n",
        "            ]].drop_duplicates().shape[0]\n",
        "\n",
        "            if calculated_combinations == total_combinations:\n",
        "                logging.info(\"Todas as combinaÃ§Ãµes de parÃ¢metros jÃ¡ foram calculadas.\")\n",
        "    except FileNotFoundError:\n",
        "        results_df = pd.DataFrame(columns=[\n",
        "            \"embedding_model\", \"reduction_model\", \"umap_params\",\n",
        "            \"clustering_model\", \"representation_model\", \"coherence\"\n",
        "        ])\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Erro ao carregar os melhores parÃ¢metros: {e}\")\n",
        "\n",
        "    # Caso as combinaÃ§Ãµes nÃ£o estejam completas, realiza a busca em grade\n",
        "    logging.info(\"\\n=== Starting Grid Search ===\")\n",
        "    logging.info(f\"Total parameter combinations: {total_combinations}\")\n",
        "\n",
        "    with tqdm(total=total_combinations, desc=\"Grid Search Progress\", unit=\"combination\") as pbar:\n",
        "        if not results_df.empty:\n",
        "            already_calculated = set(\n",
        "                tuple(row) for row in results_df[[\n",
        "                    \"embedding_model\", \"reduction_model\", \"umap_params\",\n",
        "                    \"clustering_model\", \"representation_model\"\n",
        "                ]].drop_duplicates().itertuples(index=False, name=None)\n",
        "            )\n",
        "        else:\n",
        "            already_calculated = set()\n",
        "\n",
        "        for params in all_combinations:\n",
        "            param_key = {\n",
        "                \"embedding_model\": params[0],\n",
        "                \"reduction_model\": params[1],\n",
        "                \"umap_params\": str(params[2]),\n",
        "                \"clustering_model\": params[3],\n",
        "                \"representation_model\": params[4]\n",
        "            }\n",
        "\n",
        "            if tuple(param_key.values()) in already_calculated:\n",
        "                existing_coherence = results_df.loc[\n",
        "                    (results_df[list(param_key)] == pd.Series(param_key)).all(axis=1), \"coherence\"\n",
        "                ].values[0]\n",
        "                logging.info(f\"Modelo jÃ¡ calculado: {param_key} | Coherence: {existing_coherence}\")\n",
        "                pbar.update(1)\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                logging.info(f\"Calculando novos parÃ¢metros: {param_key}\")\n",
        "                embedding_model = get_embedding_model(param_key[\"embedding_model\"])\n",
        "                reduction_model = get_reduction_model(param_key[\"reduction_model\"], eval(param_key[\"umap_params\"]))\n",
        "                clustering_model = get_clustering_model(param_key[\"clustering_model\"], 30)\n",
        "                tfidf_vectorizer = TfidfVectorizer(stop_words='english', smooth_idf=True)\n",
        "                representation_model = get_representation_model(param_key[\"representation_model\"], None)\n",
        "\n",
        "                logging.info(\"Initializing model...\")\n",
        "                topic_model = BERTopic(\n",
        "                    n_gram_range=2,\n",
        "                    language=\"english\",\n",
        "                    umap_model=reduction_model,\n",
        "                    hdbscan_model=clustering_model,\n",
        "                    vectorizer_model=tfidf_vectorizer,\n",
        "                    representation_model=representation_model,\n",
        "                    embedding_model=embedding_model,\n",
        "                    min_topic_size=100,\n",
        "                )\n",
        "\n",
        "                logging.info(\"Fitting model...\")\n",
        "                topic_model.fit_transform(sentences)\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Erro com parÃ¢metros {param_key}: {e}\")\n",
        "                pbar.update(1)\n",
        "                continue\n",
        "\n",
        "            logging.info(\"Calculating coherence...\")\n",
        "            coherence_score = calculate_coherence(topic_model, sentences)\n",
        "            new_result = {**param_key, \"coherence\": coherence_score}\n",
        "            results_df = pd.concat([results_df, pd.DataFrame([new_result])], ignore_index=True)\n",
        "            results_df.to_csv(results_file, index=False)\n",
        "\n",
        "            if coherence_score > best_coherence:\n",
        "                best_coherence = coherence_score\n",
        "\n",
        "            del embedding_model, reduction_model, clustering_model, tfidf_vectorizer, representation_model, topic_model\n",
        "            gc.collect()\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "    return results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (2.7.0)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (0.30.2)\n",
            "Requirement already satisfied: Pillow in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: colorama in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.24.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vmart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
            "[notice] To update, run: C:\\Users\\vmart\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "zntmFYVyiAjc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-14 19:27:08,391 - INFO - \n",
            "=== Starting Grid Search ===\n",
            "2025-06-14 19:27:08,391 - INFO - Total parameter combinations: 48\n",
            "Grid Search Progress:   0%|          | 0/48 [00:00<?, ?combination/s]2025-06-14 19:27:08,393 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:27:08,397 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:27:08,398 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:27:18,471 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:27:38,624 - ERROR - Erro com parÃ¢metros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:   2%|â–         | 1/48 [00:30<23:40, 30.23s/combination]2025-06-14 19:27:38,626 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:27:38,631 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:27:38,632 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:27:48,697 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:28:08,779 - ERROR - Erro com parÃ¢metros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:   4%|â–         | 2/48 [01:00<23:08, 30.19s/combination]2025-06-14 19:28:08,782 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:28:08,788 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:28:08,788 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:28:18,849 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:28:39,006 - ERROR - Erro com parÃ¢metros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:   6%|â–‹         | 3/48 [01:30<22:39, 30.21s/combination]2025-06-14 19:28:39,011 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:28:39,016 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:28:39,017 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:28:49,064 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:29:09,183 - ERROR - Erro com parÃ¢metros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:   8%|â–Š         | 4/48 [02:00<22:08, 30.19s/combination]2025-06-14 19:29:09,185 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:29:09,188 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:29:09,189 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:29:19,266 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:29:39,361 - ERROR - Erro com parÃ¢metros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:  10%|â–ˆ         | 5/48 [02:30<21:38, 30.19s/combination]2025-06-14 19:29:39,363 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:29:39,367 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:29:39,368 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:29:49,427 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:30:09,578 - ERROR - Erro com parÃ¢metros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:  12%|â–ˆâ–Ž        | 6/48 [03:01<21:08, 30.20s/combination]2025-06-14 19:30:09,582 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:30:09,589 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:30:09,590 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:30:19,654 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:30:39,764 - ERROR - Erro com parÃ¢metros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:  15%|â–ˆâ–        | 7/48 [03:31<20:37, 30.19s/combination]2025-06-14 19:30:39,768 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:30:39,774 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:30:39,775 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:30:49,827 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:31:09,952 - ERROR - Erro com parÃ¢metros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:  17%|â–ˆâ–‹        | 8/48 [04:01<20:07, 30.19s/combination]2025-06-14 19:31:09,955 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:31:09,961 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:31:09,963 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:31:20,043 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:31:40,169 - ERROR - Erro com parÃ¢metros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:  19%|â–ˆâ–‰        | 9/48 [04:31<19:37, 30.20s/combination]2025-06-14 19:31:40,172 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:31:40,180 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:31:40,181 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:31:50,239 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:32:10,318 - ERROR - Erro com parÃ¢metros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:  21%|â–ˆâ–ˆ        | 10/48 [05:01<19:06, 30.18s/combination]2025-06-14 19:32:10,319 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:32:10,323 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:32:10,324 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:32:20,389 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:32:35,621 - ERROR - Erro com parÃ¢metros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}: Unrecognized model in sentence-transformers/all-MiniLM-L6-v2. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, aria, aria_text, audio-spectrogram-transformer, autoformer, aya_vision, bamba, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, cohere2, colpali, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dab-detr, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deepseek_v3, deformable_detr, deit, depth_anything, depth_pro, deta, detr, diffllama, dinat, dinov2, dinov2_with_registers, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, emu3, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, gemma3, gemma3_text, git, glm, glm4, glpn, got_ocr2, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, granitemoeshared, granitevision, graphormer, grounding-dino, groupvit, helium, hiera, hubert, ibert, idefics, idefics2, idefics3, idefics3_vision, ijepa, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llama4, llama4_text, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mistral3, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, modernbert, moonshine, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phi4_multimodal, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prompt_depth_anything, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_5_vl, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, qwen3, qwen3_moe, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rt_detr_v2, rwkv, sam, sam_vision_model, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, shieldgemma2, siglip, siglip2, siglip_vision_model, smolvlm, smolvlm_vision, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superglue, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, textnet, time_series_transformer, timesformer, timm_backbone, timm_wrapper, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vitpose, vitpose_backbone, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zamba2, zoedepth\n",
            "Grid Search Progress:  23%|â–ˆâ–ˆâ–Ž       | 11/48 [05:27<17:41, 28.69s/combination]2025-06-14 19:32:35,622 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:32:35,625 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:32:35,626 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:32:45,674 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:33:05,779 - ERROR - Erro com parÃ¢metros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:  25%|â–ˆâ–ˆâ–Œ       | 12/48 [05:57<17:28, 29.14s/combination]2025-06-14 19:33:05,782 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:33:05,787 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:33:05,788 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:33:15,827 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:33:35,952 - ERROR - Erro com parÃ¢metros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:  27%|â–ˆâ–ˆâ–‹       | 13/48 [06:27<17:10, 29.45s/combination]2025-06-14 19:33:35,956 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:33:35,962 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:33:35,963 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:33:46,023 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:34:06,148 - ERROR - Erro com parÃ¢metros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:  29%|â–ˆâ–ˆâ–‰       | 14/48 [06:57<16:48, 29.68s/combination]2025-06-14 19:34:06,150 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:34:06,153 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:34:06,154 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:34:16,212 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 19:34:31,626 - ERROR - Erro com parÃ¢metros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:  31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [07:23<15:37, 28.41s/combination]2025-06-14 19:34:31,628 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 19:34:31,635 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 19:34:31,637 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-14 19:34:41,685 - WARNING - No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "2025-06-14 22:35:02,155 - ERROR - Erro com parÃ¢metros {'embedding_model': 'all-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\n",
            "Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.\n",
            "Grid Search Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [3:07:53<29:09:15, 3279.85s/combination]2025-06-14 22:35:02,156 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-14 22:35:02,159 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-14 22:35:02,160 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "2025-06-15 11:18:50,586 - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "2025-06-15 11:18:56,227 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:18:56,228 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "2025-06-15 11:18:58,796 - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "2025-06-15 11:19:20,080 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:19:20,080 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "2025-06-15 11:19:22,860 - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "2025-06-15 11:19:29,108 - INFO - Initializing model...\n",
            "2025-06-15 11:19:29,109 - INFO - Fitting model...\n",
            "2025-06-15 11:19:42,300 - INFO - Calculating coherence...\n",
            "2025-06-15 11:19:42,302 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:19:42,308 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:19:42,309 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:19:42.309954', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:19:42,310 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:19:45,082 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:19:45,085 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:19:47,209 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:19:47,218 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [15:52:39<138:33:50, 16091.31s/combination]2025-06-15 11:19:47,511 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:19:47,514 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:19:47,515 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:19:49,078 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:19:49,079 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:19:51,024 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:19:51,025 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:19:53,938 - INFO - Initializing model...\n",
            "2025-06-15 11:19:53,939 - INFO - Fitting model...\n",
            "  File \"C:\\Users\\vmart\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
            "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n",
            "2025-06-15 11:20:00,634 - INFO - Calculating coherence...\n",
            "2025-06-15 11:20:00,635 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:20:00,641 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:20:00,642 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:20:00.642579', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:20:00,643 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:20:09,220 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:20:09,222 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:20:09,407 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:20:09,417 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [15:53:01<93:51:22, 11262.74s/combination] 2025-06-15 11:20:09,818 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:20:09,821 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:20:09,822 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:20:11,709 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:20:11,709 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:20:15,088 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:20:15,089 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:20:17,136 - INFO - Initializing model...\n",
            "2025-06-15 11:20:17,137 - INFO - Fitting model...\n",
            "2025-06-15 11:20:23,790 - INFO - Calculating coherence...\n",
            "2025-06-15 11:20:23,792 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:20:23,798 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:20:23,799 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:20:23.799193', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:20:23,800 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:20:24,990 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:20:24,993 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:20:26,910 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:20:26,916 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [15:53:18<63:31:13, 7885.30s/combination] 2025-06-15 11:20:27,240 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:20:27,244 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:20:27,245 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:20:30,148 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:20:30,149 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:20:32,193 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:20:32,194 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:20:34,182 - INFO - Initializing model...\n",
            "2025-06-15 11:20:34,184 - INFO - Fitting model...\n",
            "2025-06-15 11:20:41,370 - INFO - Calculating coherence...\n",
            "2025-06-15 11:20:41,372 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:20:41,381 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:20:41,382 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:20:41.382947', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:20:41,383 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:20:50,844 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:20:50,845 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:20:51,020 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:20:51,032 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [15:53:43<42:58:22, 5525.10s/combination]2025-06-15 11:20:51,489 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:20:51,491 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:20:51,493 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:20:53,701 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:20:53,702 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:20:55,848 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:20:55,848 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:20:57,996 - INFO - Initializing model...\n",
            "2025-06-15 11:20:57,998 - INFO - Fitting model...\n",
            "2025-06-15 11:21:04,586 - INFO - Calculating coherence...\n",
            "2025-06-15 11:21:04,587 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:21:04,594 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:21:04,595 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:21:04.595181', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:21:04,596 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:21:05,744 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:21:05,747 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:21:07,646 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:21:07,651 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [15:53:59<29:02:12, 3871.59s/combination]2025-06-15 11:21:07,955 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:21:07,958 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:21:07,959 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:21:09,881 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:21:09,882 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:21:11,821 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:21:11,822 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:21:13,665 - INFO - Initializing model...\n",
            "2025-06-15 11:21:13,668 - INFO - Fitting model...\n",
            "2025-06-15 11:21:20,793 - INFO - Calculating coherence...\n",
            "2025-06-15 11:21:20,795 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:21:20,805 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:21:20,806 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:21:20.806464', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:21:20,808 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:21:30,317 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:21:30,318 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:21:30,482 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:21:30,494 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [15:54:22<19:37:10, 2716.56s/combination]2025-06-15 11:21:30,949 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:21:30,952 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:21:30,953 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:21:32,827 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:21:32,827 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:21:35,075 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:21:35,076 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:21:37,115 - INFO - Initializing model...\n",
            "2025-06-15 11:21:37,116 - INFO - Fitting model...\n",
            "2025-06-15 11:21:44,365 - INFO - Calculating coherence...\n",
            "2025-06-15 11:21:44,367 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:21:44,373 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:21:44,374 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:21:44.374194', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:21:44,375 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:21:45,569 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:21:45,571 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:21:47,623 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:21:47,629 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [15:54:39<13:14:21, 1906.46s/combination]2025-06-15 11:21:47,931 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:21:47,935 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:21:47,936 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:21:50,435 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:21:50,435 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:21:52,579 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:21:52,580 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:21:54,421 - INFO - Initializing model...\n",
            "2025-06-15 11:21:54,424 - INFO - Fitting model...\n",
            "2025-06-15 11:22:06,237 - INFO - Calculating coherence...\n",
            "2025-06-15 11:22:06,241 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:22:06,264 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:22:06,272 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:22:06.272344', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:22:06,280 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:22:18,399 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:22:18,402 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:22:18,615 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:22:18,627 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [15:55:11<8:57:33, 1343.89s/combination] 2025-06-15 11:22:19,526 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:22:19,535 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:22:19,537 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:22:21,405 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:22:21,406 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:22:23,819 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:22:23,821 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:22:25,960 - INFO - Initializing model...\n",
            "2025-06-15 11:22:25,962 - INFO - Fitting model...\n",
            "2025-06-15 11:23:20,690 - INFO - Calculating coherence...\n",
            "2025-06-15 11:23:20,693 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:23:20,709 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:23:20,710 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:23:20.710637', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:23:20,712 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:23:22,175 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:23:22,177 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:23:24,159 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:23:24,170 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [15:56:16<6:08:06, 960.30s/combination] 2025-06-15 11:23:24,948 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:23:24,956 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:23:24,958 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:23:26,676 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:23:26,677 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:23:28,798 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:23:28,955 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:23:30,621 - INFO - Initializing model...\n",
            "2025-06-15 11:23:30,622 - INFO - Fitting model...\n",
            "2025-06-15 11:24:37,268 - INFO - Calculating coherence...\n",
            "2025-06-15 11:24:37,271 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:24:37,282 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:24:37,284 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:24:37.284006', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:24:37,289 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:24:51,474 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:24:51,479 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:24:52,030 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:24:52,055 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [15:57:45<4:16:15, 698.88s/combination]2025-06-15 11:24:53,915 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:24:53,926 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:24:53,927 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:24:55,989 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:24:55,991 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:24:58,209 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:24:58,210 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:25:00,496 - INFO - Initializing model...\n",
            "2025-06-15 11:25:00,498 - INFO - Fitting model...\n",
            "2025-06-15 11:26:15,239 - INFO - Calculating coherence...\n",
            "2025-06-15 11:26:15,241 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:26:15,353 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:26:15,354 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:26:15.354622', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:26:15,356 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:26:17,845 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:26:17,848 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:26:19,544 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:26:19,556 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [15:59:12<3:00:18, 515.15s/combination]2025-06-15 11:26:20,407 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:26:20,415 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:26:20,416 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:26:22,019 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:26:22,021 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:26:24,365 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:26:24,366 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:26:26,321 - INFO - Initializing model...\n",
            "2025-06-15 11:26:26,322 - INFO - Fitting model...\n",
            "2025-06-15 11:27:25,121 - INFO - Calculating coherence...\n",
            "2025-06-15 11:27:25,124 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:27:25,143 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:27:25,145 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:27:25.145949', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:27:25,149 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:27:36,150 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:27:36,154 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:27:36,413 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:27:36,428 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [16:00:28<2:07:53, 383.68s/combination]2025-06-15 11:27:37,342 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:27:37,352 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:27:37,353 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:27:38,948 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:27:38,950 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:27:41,373 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:27:41,374 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:27:43,716 - INFO - Initializing model...\n",
            "2025-06-15 11:27:43,718 - INFO - Fitting model...\n",
            "2025-06-15 11:28:36,789 - INFO - Calculating coherence...\n",
            "2025-06-15 11:28:36,792 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:28:36,809 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:28:36,812 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:28:36.812283', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:28:36,813 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:28:38,185 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:28:38,187 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:28:39,906 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:28:39,914 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [16:01:32<1:31:02, 287.51s/combination]2025-06-15 11:28:40,480 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:28:40,490 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:28:40,492 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:28:42,610 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:28:42,611 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:28:44,840 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:28:44,841 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:28:46,800 - INFO - Initializing model...\n",
            "2025-06-15 11:28:46,802 - INFO - Fitting model...\n",
            "2025-06-15 11:29:47,725 - INFO - Calculating coherence...\n",
            "2025-06-15 11:29:47,729 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:29:47,745 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:29:47,747 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:29:47.747692', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:29:47,750 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:29:59,464 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:29:59,467 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:29:59,732 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:29:59,746 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [16:02:52<1:07:35, 225.31s/combination]2025-06-15 11:30:00,666 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:30:00,675 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:30:00,676 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:30:02,995 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:30:02,996 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:30:05,351 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:30:05,352 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:30:07,492 - INFO - Initializing model...\n",
            "2025-06-15 11:30:07,495 - INFO - Fitting model...\n",
            "2025-06-15 11:30:59,932 - INFO - Calculating coherence...\n",
            "2025-06-15 11:30:59,935 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:31:00,060 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:31:00,062 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:31:00.062386', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:31:00,064 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:31:01,428 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:31:01,431 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:31:03,379 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:31:03,386 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [16:03:55<50:05, 176.79s/combination]  2025-06-15 11:31:04,226 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'roberta', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:31:04,309 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:31:04,311 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:31:05,951 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:31:05,953 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:31:08,035 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:31:08,036 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:31:09,915 - INFO - Initializing model...\n",
            "2025-06-15 11:31:09,917 - INFO - Fitting model...\n",
            "2025-06-15 11:31:58,494 - INFO - Calculating coherence...\n",
            "2025-06-15 11:31:58,497 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:31:58,516 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:31:58,517 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:31:58.517577', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:31:58,522 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:32:09,245 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:32:09,249 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:32:09,478 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:32:09,491 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [16:05:02<38:17, 143.61s/combination]2025-06-15 11:32:10,413 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:32:10,422 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:32:10,424 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:32:12,341 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:32:12,342 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:32:14,688 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:32:14,690 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:32:16,828 - INFO - Initializing model...\n",
            "2025-06-15 11:32:16,830 - INFO - Fitting model...\n",
            "2025-06-15 11:32:21,101 - INFO - Calculating coherence...\n",
            "2025-06-15 11:32:21,104 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:32:21,122 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:32:21,125 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:32:21.125265', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:32:21,127 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:32:22,355 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:32:22,358 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:32:24,305 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:32:24,317 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [16:05:16<26:13, 104.93s/combination]2025-06-15 11:32:25,110 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:32:25,118 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:32:25,119 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:32:27,180 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:32:27,181 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:32:29,843 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:32:29,845 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:32:31,984 - INFO - Initializing model...\n",
            "2025-06-15 11:32:31,986 - INFO - Fitting model...\n",
            "2025-06-15 11:32:37,094 - INFO - Calculating coherence...\n",
            "2025-06-15 11:32:37,097 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:32:37,116 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:32:37,117 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:32:37.117982', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:32:37,123 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:32:48,004 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:32:48,007 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:32:48,298 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:32:48,319 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [16:05:40<18:49, 80.71s/combination] 2025-06-15 11:32:49,296 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:32:49,306 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:32:49,307 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:32:51,344 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:32:51,345 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:32:53,541 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:32:53,543 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:32:55,501 - INFO - Initializing model...\n",
            "2025-06-15 11:32:55,503 - INFO - Fitting model...\n",
            "2025-06-15 11:33:03,473 - INFO - Calculating coherence...\n",
            "2025-06-15 11:33:03,476 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:33:03,494 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:33:03,495 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:33:03.495271', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:33:03,497 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:33:04,808 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:33:04,811 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:33:06,655 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:33:06,662 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [16:05:58<13:24, 61.90s/combination]2025-06-15 11:33:07,295 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:33:07,305 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:33:07,306 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:33:09,370 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:33:09,371 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:33:11,727 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:33:11,728 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:33:13,521 - INFO - Initializing model...\n",
            "2025-06-15 11:33:13,523 - INFO - Fitting model...\n",
            "2025-06-15 11:33:20,538 - INFO - Calculating coherence...\n",
            "2025-06-15 11:33:20,541 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:33:20,562 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:33:20,563 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:33:20.563563', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:33:20,566 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:33:31,757 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:33:31,760 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:33:32,030 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:33:32,047 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [16:06:24<10:12, 51.05s/combination]2025-06-15 11:33:33,023 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:33:33,033 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:33:33,034 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:33:34,970 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:33:34,971 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:33:37,020 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:33:37,021 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:33:39,058 - INFO - Initializing model...\n",
            "2025-06-15 11:33:39,060 - INFO - Fitting model...\n",
            "2025-06-15 11:33:44,373 - INFO - Calculating coherence...\n",
            "2025-06-15 11:33:44,377 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:33:44,398 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:33:44,400 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:33:44.400007', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:33:44,404 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:33:45,796 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:33:45,798 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:33:47,759 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:33:47,769 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [16:06:40<07:23, 40.35s/combination]2025-06-15 11:33:48,419 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:33:48,432 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:33:48,434 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:33:50,724 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:33:50,726 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:33:52,689 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:33:52,690 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:33:54,631 - INFO - Initializing model...\n",
            "2025-06-15 11:33:54,633 - INFO - Fitting model...\n",
            "2025-06-15 11:34:00,592 - INFO - Calculating coherence...\n",
            "2025-06-15 11:34:00,595 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:34:00,615 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:34:00,617 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:34:00.617797', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:34:00,623 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:34:11,892 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:34:11,895 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:34:12,128 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:34:12,144 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [16:07:04<05:56, 35.63s/combination]2025-06-15 11:34:13,034 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:34:13,043 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:34:13,045 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:34:15,318 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:34:15,319 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:34:19,619 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:34:19,621 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:34:21,660 - INFO - Initializing model...\n",
            "2025-06-15 11:34:21,661 - INFO - Fitting model...\n",
            "2025-06-15 11:34:27,513 - INFO - Calculating coherence...\n",
            "2025-06-15 11:34:27,517 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:34:27,538 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:34:27,540 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:34:27.540711', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:34:27,543 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:34:28,852 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:34:28,854 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:34:30,766 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:34:30,774 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [16:07:23<04:34, 30.45s/combination]2025-06-15 11:34:31,405 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.1}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:34:31,413 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:34:31,415 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:34:33,100 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:34:33,102 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:34:35,536 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:34:35,538 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:34:37,532 - INFO - Initializing model...\n",
            "2025-06-15 11:34:37,534 - INFO - Fitting model...\n",
            "2025-06-15 11:34:43,167 - INFO - Calculating coherence...\n",
            "2025-06-15 11:34:43,171 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:34:43,223 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:34:43,233 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:34:43.231917', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:34:43,239 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:34:53,896 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:34:53,900 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:34:54,140 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:34:54,158 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [16:07:46<03:47, 28.41s/combination]2025-06-15 11:34:55,046 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:34:55,055 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:34:55,057 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:34:57,526 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:34:57,529 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:34:59,912 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:34:59,914 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:35:01,799 - INFO - Initializing model...\n",
            "2025-06-15 11:35:01,801 - INFO - Fitting model...\n",
            "2025-06-15 11:35:10,542 - INFO - Calculating coherence...\n",
            "2025-06-15 11:35:10,545 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:35:10,562 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:35:10,563 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:35:10.563739', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:35:10,565 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:35:11,794 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:35:11,796 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:35:13,683 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:35:13,692 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [16:08:05<02:59, 25.67s/combination]2025-06-15 11:35:14,340 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 5, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:35:14,349 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:35:14,350 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:35:16,438 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:35:16,440 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:35:18,804 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:35:18,805 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:35:20,845 - INFO - Initializing model...\n",
            "2025-06-15 11:35:20,847 - INFO - Fitting model...\n",
            "2025-06-15 11:35:25,618 - INFO - Calculating coherence...\n",
            "2025-06-15 11:35:25,620 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:35:25,641 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:35:25,642 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:35:25.642373', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:35:25,646 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:35:37,021 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:35:37,026 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:35:37,310 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:35:37,327 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [16:08:30<02:31, 25.25s/combination]2025-06-15 11:35:38,587 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:35:38,596 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:35:38,597 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:35:40,585 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:35:40,587 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:35:42,873 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:35:42,875 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:35:44,653 - INFO - Initializing model...\n",
            "2025-06-15 11:35:44,657 - INFO - Fitting model...\n",
            "2025-06-15 11:35:49,878 - INFO - Calculating coherence...\n",
            "2025-06-15 11:35:49,882 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:35:49,900 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:35:49,903 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:35:49.903891', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:35:49,943 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:35:51,394 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:35:51,396 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:35:53,134 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:35:53,142 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [16:08:45<01:50, 22.19s/combination]2025-06-15 11:35:53,659 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 20, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:35:53,668 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:35:53,670 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:35:55,615 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:35:55,617 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:35:57,721 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:35:57,722 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:35:59,762 - INFO - Initializing model...\n",
            "2025-06-15 11:35:59,764 - INFO - Fitting model...\n",
            "2025-06-15 11:36:04,300 - INFO - Calculating coherence...\n",
            "2025-06-15 11:36:04,304 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:36:04,324 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:36:04,326 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:36:04.326591', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:36:04,330 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:36:14,843 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:36:14,846 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:36:15,065 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:36:15,080 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [16:09:07<01:28, 22.23s/combination]2025-06-15 11:36:15,990 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:36:15,998 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:36:16,000 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:36:18,406 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:36:18,407 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:36:20,558 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:36:20,560 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:36:22,702 - INFO - Initializing model...\n",
            "2025-06-15 11:36:22,704 - INFO - Fitting model...\n",
            "2025-06-15 11:36:27,176 - INFO - Calculating coherence...\n",
            "2025-06-15 11:36:27,179 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:36:27,199 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:36:27,202 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:36:27.202624', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:36:27,205 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:36:28,407 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:36:28,410 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:36:30,212 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:36:30,224 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [16:09:22<01:00, 20.02s/combination]2025-06-15 11:36:30,838 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:36:30,848 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:36:30,849 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:36:33,306 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:36:33,307 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:36:35,611 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:36:35,613 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:36:37,753 - INFO - Initializing model...\n",
            "2025-06-15 11:36:37,755 - INFO - Fitting model...\n",
            "2025-06-15 11:36:43,250 - INFO - Calculating coherence...\n",
            "2025-06-15 11:36:43,253 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:36:43,273 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:36:43,275 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:36:43.275188', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:36:43,276 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:36:54,095 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:36:54,099 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:36:54,359 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:36:54,372 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [16:09:46<00:42, 21.34s/combination]2025-06-15 11:36:55,266 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'hdbscan', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:36:55,275 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:36:55,276 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:36:57,243 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:36:57,245 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:36:59,675 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:36:59,676 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:37:01,512 - INFO - Initializing model...\n",
            "2025-06-15 11:37:01,514 - INFO - Fitting model...\n",
            "2025-06-15 11:37:06,763 - INFO - Calculating coherence...\n",
            "2025-06-15 11:37:06,765 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:37:06,783 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:37:06,793 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:37:06.793207', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:37:06,796 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:37:08,170 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:37:08,173 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:37:10,111 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:37:10,122 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [16:10:02<00:19, 19.58s/combination]2025-06-15 11:37:10,740 - INFO - Calculando novos parÃ¢metros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': \"{'n_neighbors': 100, 'n_components': 5, 'min_dist': 0.5}\", 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "2025-06-15 11:37:10,751 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:37:10,752 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "2025-06-15 11:37:12,781 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:37:12,783 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:37:15,138 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:37:15,140 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n",
            "2025-06-15 11:37:17,276 - INFO - Initializing model...\n",
            "2025-06-15 11:37:17,279 - INFO - Fitting model...\n",
            "2025-06-15 11:37:23,663 - INFO - Calculating coherence...\n",
            "2025-06-15 11:37:23,666 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 11:37:23,685 - INFO - built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\n",
            "2025-06-15 11:37:23,687 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<1887 unique tokens: ['#antiotario', '#rafaelaires', '#redpillbrasil', 'adquira', 'agora']...> from 100 documents (total 13171 corpus positions)\", 'datetime': '2025-06-15T11:37:23.687444', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 11:37:23,698 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 11:37:35,011 - INFO - 1 batches submitted to accumulate stats from 64 documents (1246 virtual)\n",
            "2025-06-15 11:37:35,014 - INFO - 2 batches submitted to accumulate stats from 128 documents (2271 virtual)\n",
            "2025-06-15 11:37:35,294 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 11:37:35,310 - INFO - accumulated word occurrence stats for 5713 virtual documents\n",
            "Grid Search Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [16:10:27<00:00, 1213.08s/combination]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>embedding_model</th>\n",
              "      <th>reduction_model</th>\n",
              "      <th>umap_params</th>\n",
              "      <th>clustering_model</th>\n",
              "      <th>representation_model</th>\n",
              "      <th>coherence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.509318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.557656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.550874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.566453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.554769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.557588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.549375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.566509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.514351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.386301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.546947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.555407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.495577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.472862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.499655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.592118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.519590</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            embedding_model reduction_model  \\\n",
              "0                   roberta            umap   \n",
              "1                   roberta            umap   \n",
              "2                   roberta            umap   \n",
              "3                   roberta            umap   \n",
              "4                   roberta            umap   \n",
              "5                   roberta            umap   \n",
              "6                   roberta            umap   \n",
              "7                   roberta            umap   \n",
              "8                   roberta            umap   \n",
              "9                   roberta            umap   \n",
              "10                  roberta            umap   \n",
              "11                  roberta            umap   \n",
              "12                  roberta            umap   \n",
              "13                  roberta            umap   \n",
              "14                  roberta            umap   \n",
              "15                  roberta            umap   \n",
              "16  paraphrase-MiniLM-L6-v2            umap   \n",
              "17  paraphrase-MiniLM-L6-v2            umap   \n",
              "18  paraphrase-MiniLM-L6-v2            umap   \n",
              "19  paraphrase-MiniLM-L6-v2            umap   \n",
              "20  paraphrase-MiniLM-L6-v2            umap   \n",
              "21  paraphrase-MiniLM-L6-v2            umap   \n",
              "22  paraphrase-MiniLM-L6-v2            umap   \n",
              "23  paraphrase-MiniLM-L6-v2            umap   \n",
              "24  paraphrase-MiniLM-L6-v2            umap   \n",
              "25  paraphrase-MiniLM-L6-v2            umap   \n",
              "26  paraphrase-MiniLM-L6-v2            umap   \n",
              "27  paraphrase-MiniLM-L6-v2            umap   \n",
              "28  paraphrase-MiniLM-L6-v2            umap   \n",
              "29  paraphrase-MiniLM-L6-v2            umap   \n",
              "30  paraphrase-MiniLM-L6-v2            umap   \n",
              "31  paraphrase-MiniLM-L6-v2            umap   \n",
              "\n",
              "                                          umap_params clustering_model  \\\n",
              "0   {'n_neighbors': 5, 'n_components': 5, 'min_dis...          hdbscan   \n",
              "1   {'n_neighbors': 5, 'n_components': 5, 'min_dis...           kmeans   \n",
              "2   {'n_neighbors': 20, 'n_components': 5, 'min_di...          hdbscan   \n",
              "3   {'n_neighbors': 20, 'n_components': 5, 'min_di...           kmeans   \n",
              "4   {'n_neighbors': 50, 'n_components': 5, 'min_di...          hdbscan   \n",
              "5   {'n_neighbors': 50, 'n_components': 5, 'min_di...           kmeans   \n",
              "6   {'n_neighbors': 100, 'n_components': 5, 'min_d...          hdbscan   \n",
              "7   {'n_neighbors': 100, 'n_components': 5, 'min_d...           kmeans   \n",
              "8   {'n_neighbors': 5, 'n_components': 5, 'min_dis...          hdbscan   \n",
              "9   {'n_neighbors': 5, 'n_components': 5, 'min_dis...           kmeans   \n",
              "10  {'n_neighbors': 20, 'n_components': 5, 'min_di...          hdbscan   \n",
              "11  {'n_neighbors': 20, 'n_components': 5, 'min_di...           kmeans   \n",
              "12  {'n_neighbors': 50, 'n_components': 5, 'min_di...          hdbscan   \n",
              "13  {'n_neighbors': 50, 'n_components': 5, 'min_di...           kmeans   \n",
              "14  {'n_neighbors': 100, 'n_components': 5, 'min_d...          hdbscan   \n",
              "15  {'n_neighbors': 100, 'n_components': 5, 'min_d...           kmeans   \n",
              "16  {'n_neighbors': 5, 'n_components': 5, 'min_dis...          hdbscan   \n",
              "17  {'n_neighbors': 5, 'n_components': 5, 'min_dis...           kmeans   \n",
              "18  {'n_neighbors': 20, 'n_components': 5, 'min_di...          hdbscan   \n",
              "19  {'n_neighbors': 20, 'n_components': 5, 'min_di...           kmeans   \n",
              "20  {'n_neighbors': 50, 'n_components': 5, 'min_di...          hdbscan   \n",
              "21  {'n_neighbors': 50, 'n_components': 5, 'min_di...           kmeans   \n",
              "22  {'n_neighbors': 100, 'n_components': 5, 'min_d...          hdbscan   \n",
              "23  {'n_neighbors': 100, 'n_components': 5, 'min_d...           kmeans   \n",
              "24  {'n_neighbors': 5, 'n_components': 5, 'min_dis...          hdbscan   \n",
              "25  {'n_neighbors': 5, 'n_components': 5, 'min_dis...           kmeans   \n",
              "26  {'n_neighbors': 20, 'n_components': 5, 'min_di...          hdbscan   \n",
              "27  {'n_neighbors': 20, 'n_components': 5, 'min_di...           kmeans   \n",
              "28  {'n_neighbors': 50, 'n_components': 5, 'min_di...          hdbscan   \n",
              "29  {'n_neighbors': 50, 'n_components': 5, 'min_di...           kmeans   \n",
              "30  {'n_neighbors': 100, 'n_components': 5, 'min_d...          hdbscan   \n",
              "31  {'n_neighbors': 100, 'n_components': 5, 'min_d...           kmeans   \n",
              "\n",
              "          representation_model  coherence  \n",
              "0   maximal_marginal_relevance   0.377603  \n",
              "1   maximal_marginal_relevance   0.509318  \n",
              "2   maximal_marginal_relevance   0.377603  \n",
              "3   maximal_marginal_relevance   0.557656  \n",
              "4   maximal_marginal_relevance   0.377603  \n",
              "5   maximal_marginal_relevance   0.550874  \n",
              "6   maximal_marginal_relevance   0.377603  \n",
              "7   maximal_marginal_relevance   0.566453  \n",
              "8   maximal_marginal_relevance   0.377603  \n",
              "9   maximal_marginal_relevance   0.554769  \n",
              "10  maximal_marginal_relevance   0.377603  \n",
              "11  maximal_marginal_relevance   0.557588  \n",
              "12  maximal_marginal_relevance   0.377603  \n",
              "13  maximal_marginal_relevance   0.549375  \n",
              "14  maximal_marginal_relevance   0.377603  \n",
              "15  maximal_marginal_relevance   0.566509  \n",
              "16  maximal_marginal_relevance   0.377603  \n",
              "17  maximal_marginal_relevance   0.514351  \n",
              "18  maximal_marginal_relevance   0.386301  \n",
              "19  maximal_marginal_relevance   0.546947  \n",
              "20  maximal_marginal_relevance   0.377603  \n",
              "21  maximal_marginal_relevance   0.555407  \n",
              "22  maximal_marginal_relevance   0.377603  \n",
              "23  maximal_marginal_relevance   0.495577  \n",
              "24  maximal_marginal_relevance   0.377603  \n",
              "25  maximal_marginal_relevance   0.472862  \n",
              "26  maximal_marginal_relevance   0.377603  \n",
              "27  maximal_marginal_relevance   0.499655  \n",
              "28  maximal_marginal_relevance   0.377603  \n",
              "29  maximal_marginal_relevance   0.592118  \n",
              "30  maximal_marginal_relevance   0.377603  \n",
              "31  maximal_marginal_relevance   0.519590  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "perform_grid_search(train_sentences, param_grid, results_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>embedding_model</th>\n",
              "      <th>reduction_model</th>\n",
              "      <th>umap_params</th>\n",
              "      <th>clustering_model</th>\n",
              "      <th>representation_model</th>\n",
              "      <th>coherence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.592118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.566509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.566453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.557656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.557588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.555407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.554769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.550874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.549375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.546947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.519590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.514351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.509318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.499655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.495577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>kmeans</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.472862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.386301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 100, 'n_components': 5, 'min_d...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 50, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>roberta</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 20, 'n_components': 5, 'min_di...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>paraphrase-MiniLM-L6-v2</td>\n",
              "      <td>umap</td>\n",
              "      <td>{'n_neighbors': 5, 'n_components': 5, 'min_dis...</td>\n",
              "      <td>hdbscan</td>\n",
              "      <td>maximal_marginal_relevance</td>\n",
              "      <td>0.377603</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            embedding_model reduction_model  \\\n",
              "29  paraphrase-MiniLM-L6-v2            umap   \n",
              "15                  roberta            umap   \n",
              "7                   roberta            umap   \n",
              "3                   roberta            umap   \n",
              "11                  roberta            umap   \n",
              "21  paraphrase-MiniLM-L6-v2            umap   \n",
              "9                   roberta            umap   \n",
              "5                   roberta            umap   \n",
              "13                  roberta            umap   \n",
              "19  paraphrase-MiniLM-L6-v2            umap   \n",
              "31  paraphrase-MiniLM-L6-v2            umap   \n",
              "17  paraphrase-MiniLM-L6-v2            umap   \n",
              "1                   roberta            umap   \n",
              "27  paraphrase-MiniLM-L6-v2            umap   \n",
              "23  paraphrase-MiniLM-L6-v2            umap   \n",
              "25  paraphrase-MiniLM-L6-v2            umap   \n",
              "18  paraphrase-MiniLM-L6-v2            umap   \n",
              "28  paraphrase-MiniLM-L6-v2            umap   \n",
              "26  paraphrase-MiniLM-L6-v2            umap   \n",
              "22  paraphrase-MiniLM-L6-v2            umap   \n",
              "24  paraphrase-MiniLM-L6-v2            umap   \n",
              "30  paraphrase-MiniLM-L6-v2            umap   \n",
              "0                   roberta            umap   \n",
              "20  paraphrase-MiniLM-L6-v2            umap   \n",
              "14                  roberta            umap   \n",
              "12                  roberta            umap   \n",
              "10                  roberta            umap   \n",
              "8                   roberta            umap   \n",
              "6                   roberta            umap   \n",
              "4                   roberta            umap   \n",
              "2                   roberta            umap   \n",
              "16  paraphrase-MiniLM-L6-v2            umap   \n",
              "\n",
              "                                          umap_params clustering_model  \\\n",
              "29  {'n_neighbors': 50, 'n_components': 5, 'min_di...           kmeans   \n",
              "15  {'n_neighbors': 100, 'n_components': 5, 'min_d...           kmeans   \n",
              "7   {'n_neighbors': 100, 'n_components': 5, 'min_d...           kmeans   \n",
              "3   {'n_neighbors': 20, 'n_components': 5, 'min_di...           kmeans   \n",
              "11  {'n_neighbors': 20, 'n_components': 5, 'min_di...           kmeans   \n",
              "21  {'n_neighbors': 50, 'n_components': 5, 'min_di...           kmeans   \n",
              "9   {'n_neighbors': 5, 'n_components': 5, 'min_dis...           kmeans   \n",
              "5   {'n_neighbors': 50, 'n_components': 5, 'min_di...           kmeans   \n",
              "13  {'n_neighbors': 50, 'n_components': 5, 'min_di...           kmeans   \n",
              "19  {'n_neighbors': 20, 'n_components': 5, 'min_di...           kmeans   \n",
              "31  {'n_neighbors': 100, 'n_components': 5, 'min_d...           kmeans   \n",
              "17  {'n_neighbors': 5, 'n_components': 5, 'min_dis...           kmeans   \n",
              "1   {'n_neighbors': 5, 'n_components': 5, 'min_dis...           kmeans   \n",
              "27  {'n_neighbors': 20, 'n_components': 5, 'min_di...           kmeans   \n",
              "23  {'n_neighbors': 100, 'n_components': 5, 'min_d...           kmeans   \n",
              "25  {'n_neighbors': 5, 'n_components': 5, 'min_dis...           kmeans   \n",
              "18  {'n_neighbors': 20, 'n_components': 5, 'min_di...          hdbscan   \n",
              "28  {'n_neighbors': 50, 'n_components': 5, 'min_di...          hdbscan   \n",
              "26  {'n_neighbors': 20, 'n_components': 5, 'min_di...          hdbscan   \n",
              "22  {'n_neighbors': 100, 'n_components': 5, 'min_d...          hdbscan   \n",
              "24  {'n_neighbors': 5, 'n_components': 5, 'min_dis...          hdbscan   \n",
              "30  {'n_neighbors': 100, 'n_components': 5, 'min_d...          hdbscan   \n",
              "0   {'n_neighbors': 5, 'n_components': 5, 'min_dis...          hdbscan   \n",
              "20  {'n_neighbors': 50, 'n_components': 5, 'min_di...          hdbscan   \n",
              "14  {'n_neighbors': 100, 'n_components': 5, 'min_d...          hdbscan   \n",
              "12  {'n_neighbors': 50, 'n_components': 5, 'min_di...          hdbscan   \n",
              "10  {'n_neighbors': 20, 'n_components': 5, 'min_di...          hdbscan   \n",
              "8   {'n_neighbors': 5, 'n_components': 5, 'min_dis...          hdbscan   \n",
              "6   {'n_neighbors': 100, 'n_components': 5, 'min_d...          hdbscan   \n",
              "4   {'n_neighbors': 50, 'n_components': 5, 'min_di...          hdbscan   \n",
              "2   {'n_neighbors': 20, 'n_components': 5, 'min_di...          hdbscan   \n",
              "16  {'n_neighbors': 5, 'n_components': 5, 'min_dis...          hdbscan   \n",
              "\n",
              "          representation_model  coherence  \n",
              "29  maximal_marginal_relevance   0.592118  \n",
              "15  maximal_marginal_relevance   0.566509  \n",
              "7   maximal_marginal_relevance   0.566453  \n",
              "3   maximal_marginal_relevance   0.557656  \n",
              "11  maximal_marginal_relevance   0.557588  \n",
              "21  maximal_marginal_relevance   0.555407  \n",
              "9   maximal_marginal_relevance   0.554769  \n",
              "5   maximal_marginal_relevance   0.550874  \n",
              "13  maximal_marginal_relevance   0.549375  \n",
              "19  maximal_marginal_relevance   0.546947  \n",
              "31  maximal_marginal_relevance   0.519590  \n",
              "17  maximal_marginal_relevance   0.514351  \n",
              "1   maximal_marginal_relevance   0.509318  \n",
              "27  maximal_marginal_relevance   0.499655  \n",
              "23  maximal_marginal_relevance   0.495577  \n",
              "25  maximal_marginal_relevance   0.472862  \n",
              "18  maximal_marginal_relevance   0.386301  \n",
              "28  maximal_marginal_relevance   0.377603  \n",
              "26  maximal_marginal_relevance   0.377603  \n",
              "22  maximal_marginal_relevance   0.377603  \n",
              "24  maximal_marginal_relevance   0.377603  \n",
              "30  maximal_marginal_relevance   0.377603  \n",
              "0   maximal_marginal_relevance   0.377603  \n",
              "20  maximal_marginal_relevance   0.377603  \n",
              "14  maximal_marginal_relevance   0.377603  \n",
              "12  maximal_marginal_relevance   0.377603  \n",
              "10  maximal_marginal_relevance   0.377603  \n",
              "8   maximal_marginal_relevance   0.377603  \n",
              "6   maximal_marginal_relevance   0.377603  \n",
              "4   maximal_marginal_relevance   0.377603  \n",
              "2   maximal_marginal_relevance   0.377603  \n",
              "16  maximal_marginal_relevance   0.377603  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df = pd.read_csv(results_file)\n",
        "results_df.sort_values(by=\"coherence\", ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>video_id</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>channel_id</th>\n",
              "      <th>published_at</th>\n",
              "      <th>category_id</th>\n",
              "      <th>tags</th>\n",
              "      <th>view_count</th>\n",
              "      <th>...</th>\n",
              "      <th>concurrent_viewers</th>\n",
              "      <th>active_live_chat_id</th>\n",
              "      <th>recording_date</th>\n",
              "      <th>topicCategories</th>\n",
              "      <th>processing_status</th>\n",
              "      <th>parts_total</th>\n",
              "      <th>parts_processed</th>\n",
              "      <th>time_left_ms</th>\n",
              "      <th>processing_failure_reason</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>310</th>\n",
              "      <td>790</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q3ukRP_TUR4</td>\n",
              "      <td>MULHER DIZENDO QUE NÃƒO Ã‰ NORMAL HOMEM MAIS VEL...</td>\n",
              "      <td>OlÃ¡! seja bem vindo a mais um video do canal, ...</td>\n",
              "      <td>UCRmNflJuD1TxLbRlDV08_7g</td>\n",
              "      <td>2025-05-09 12:04:47</td>\n",
              "      <td>24</td>\n",
              "      <td>['red pill', 'divorcio', 'pensÃ£o socio afetiva...</td>\n",
              "      <td>654</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://en.wikipedia.org/wiki/Humour']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>mulher dizendo que nÃ£o Ã© normal homem mais vel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1kIR_cBtHjM</td>\n",
              "      <td>esses homens estÃ£o PREFERINDO A SOLITUDE â€” e n...</td>\n",
              "      <td>ðŸ’ª Use o cupom (CONSELHO) na Growth: https://ww...</td>\n",
              "      <td>UCX0VSzJ2z5l0C9wnwh5SoRw</td>\n",
              "      <td>2025-05-30 14:20:01</td>\n",
              "      <td>26</td>\n",
              "      <td>[]</td>\n",
              "      <td>20138</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://en.wikipedia.org/wiki/Society']</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>esses homens estÃ£o preferindo solitude e nÃ£o Ã©...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335</th>\n",
              "      <td>335</td>\n",
              "      <td>370.0</td>\n",
              "      <td>pPyX0NtHjLw</td>\n",
              "      <td>Gritos, reclamaÃ§Ãµes e raiva: o caminho mais rÃ¡...</td>\n",
              "      <td>#rafaelaires #antiotario #redpillbrasil\\n\\nðŸ”¥ P...</td>\n",
              "      <td>UCAYoI16-UkXemcnhC-kTvDQ</td>\n",
              "      <td>2025-05-07 21:01:00</td>\n",
              "      <td>22</td>\n",
              "      <td>[]</td>\n",
              "      <td>119</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gritos reclamaÃ§Ãµes e raiva caminho mais rÃ¡pido...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>425</th>\n",
              "      <td>425</td>\n",
              "      <td>466.0</td>\n",
              "      <td>MuScLmEv_ck</td>\n",
              "      <td>Se encontrou um Homem de valor, valorize! Apre...</td>\n",
              "      <td>#rafaelaires #antiotario #redpillbrasil\\n\\nðŸ”¥ P...</td>\n",
              "      <td>UCAYoI16-UkXemcnhC-kTvDQ</td>\n",
              "      <td>2025-05-02 15:00:41</td>\n",
              "      <td>22</td>\n",
              "      <td>[]</td>\n",
              "      <td>358</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://en.wikipedia.org/wiki/Lifestyle_(soc...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>se encontrou um homem de valor valorize aprend...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>228</td>\n",
              "      <td>255.0</td>\n",
              "      <td>w7tH6YIZyqc</td>\n",
              "      <td>MULHER DIZ QUE PAGA MARIDO PARA TER RELAÃ‡ÃƒO CO...</td>\n",
              "      <td>OlÃ¡! seja bem vindo a mais um video do canal, ...</td>\n",
              "      <td>UCRmNflJuD1TxLbRlDV08_7g</td>\n",
              "      <td>2025-05-15 01:55:09</td>\n",
              "      <td>24</td>\n",
              "      <td>['red pill', 'divorcio', 'pensÃ£o socio afetiva...</td>\n",
              "      <td>2718</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['https://en.wikipedia.org/wiki/Humour', 'http...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>mulher diz que paga marido para ter relaÃ§Ã£o co...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 38 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0.1  Unnamed: 0     video_id  \\\n",
              "310           790         NaN  Q3ukRP_TUR4   \n",
              "11             11        12.0  1kIR_cBtHjM   \n",
              "335           335       370.0  pPyX0NtHjLw   \n",
              "425           425       466.0  MuScLmEv_ck   \n",
              "228           228       255.0  w7tH6YIZyqc   \n",
              "\n",
              "                                                 title  \\\n",
              "310  MULHER DIZENDO QUE NÃƒO Ã‰ NORMAL HOMEM MAIS VEL...   \n",
              "11   esses homens estÃ£o PREFERINDO A SOLITUDE â€” e n...   \n",
              "335  Gritos, reclamaÃ§Ãµes e raiva: o caminho mais rÃ¡...   \n",
              "425  Se encontrou um Homem de valor, valorize! Apre...   \n",
              "228  MULHER DIZ QUE PAGA MARIDO PARA TER RELAÃ‡ÃƒO CO...   \n",
              "\n",
              "                                           description  \\\n",
              "310  OlÃ¡! seja bem vindo a mais um video do canal, ...   \n",
              "11   ðŸ’ª Use o cupom (CONSELHO) na Growth: https://ww...   \n",
              "335  #rafaelaires #antiotario #redpillbrasil\\n\\nðŸ”¥ P...   \n",
              "425  #rafaelaires #antiotario #redpillbrasil\\n\\nðŸ”¥ P...   \n",
              "228  OlÃ¡! seja bem vindo a mais um video do canal, ...   \n",
              "\n",
              "                   channel_id         published_at  category_id  \\\n",
              "310  UCRmNflJuD1TxLbRlDV08_7g  2025-05-09 12:04:47           24   \n",
              "11   UCX0VSzJ2z5l0C9wnwh5SoRw  2025-05-30 14:20:01           26   \n",
              "335  UCAYoI16-UkXemcnhC-kTvDQ  2025-05-07 21:01:00           22   \n",
              "425  UCAYoI16-UkXemcnhC-kTvDQ  2025-05-02 15:00:41           22   \n",
              "228  UCRmNflJuD1TxLbRlDV08_7g  2025-05-15 01:55:09           24   \n",
              "\n",
              "                                                  tags  view_count  ...  \\\n",
              "310  ['red pill', 'divorcio', 'pensÃ£o socio afetiva...         654  ...   \n",
              "11                                                  []       20138  ...   \n",
              "335                                                 []         119  ...   \n",
              "425                                                 []         358  ...   \n",
              "228  ['red pill', 'divorcio', 'pensÃ£o socio afetiva...        2718  ...   \n",
              "\n",
              "     concurrent_viewers  active_live_chat_id recording_date  \\\n",
              "310                   0                  NaN            NaN   \n",
              "11                    0                  NaN            NaN   \n",
              "335                   0                  NaN            NaN   \n",
              "425                   0                  NaN            NaN   \n",
              "228                   0                  NaN            NaN   \n",
              "\n",
              "                                       topicCategories  processing_status  \\\n",
              "310           ['https://en.wikipedia.org/wiki/Humour']                NaN   \n",
              "11           ['https://en.wikipedia.org/wiki/Society']                NaN   \n",
              "335                                                 []                NaN   \n",
              "425  ['https://en.wikipedia.org/wiki/Lifestyle_(soc...                NaN   \n",
              "228  ['https://en.wikipedia.org/wiki/Humour', 'http...                NaN   \n",
              "\n",
              "     parts_total parts_processed time_left_ms  processing_failure_reason  \\\n",
              "310            0               0            0                        NaN   \n",
              "11             0               0            0                        NaN   \n",
              "335            0               0            0                        NaN   \n",
              "425            0               0            0                        NaN   \n",
              "228            0               0            0                        NaN   \n",
              "\n",
              "                                                  text  \n",
              "310  mulher dizendo que nÃ£o Ã© normal homem mais vel...  \n",
              "11   esses homens estÃ£o preferindo solitude e nÃ£o Ã©...  \n",
              "335  gritos reclamaÃ§Ãµes e raiva caminho mais rÃ¡pido...  \n",
              "425  se encontrou um homem de valor valorize aprend...  \n",
              "228  mulher diz que paga marido para ter relaÃ§Ã£o co...  \n",
              "\n",
              "[5 rows x 38 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentences = df['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-15 11:37:36,349 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:37:36,350 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Will be calculated...\n",
            "Failed to load variable from results_2025_06_10/topics_bertopic_2025_06_10.pkl: [Errno 2] No such file or directory: 'results_2025_06_10/topics_bertopic_2025_06_10.pkl'\n",
            "Topics will be calculated...\n",
            "Failed to load variable from results_2025_06_10/probs_bertopic_2025_06_10.pkl: [Errno 2] No such file or directory: 'results_2025_06_10/probs_bertopic_2025_06_10.pkl'\n",
            "Probs will be calculated...\n",
            "Melhores parÃ¢metros: {'embedding_model': 'paraphrase-MiniLM-L6-v2', 'reduction_model': 'umap', 'umap_params': {'n_neighbors': 50, 'n_components': 5, 'min_dist': 0.5}, 'clustering_model': 'kmeans', 'representation_model': 'maximal_marginal_relevance'}\n",
            "Melhor coerÃªncia: 0.5921175102080011\n",
            "Getting embedding model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-15 11:37:38,486 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:37:38,487 - INFO - Load pretrained SentenceTransformer: roberta-base-nli-stsb-mean-tokens\n",
            "2025-06-15 11:37:40,740 - INFO - Use pytorch device_name: cpu\n",
            "2025-06-15 11:37:40,742 - INFO - Load pretrained SentenceTransformer: paraphrase-MiniLM-L6-v2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting reduction model...\n",
            "Getting clustering model...\n",
            "Getting TFIDF model...\n",
            "Getting representation model...\n",
            "Initializing model...\n",
            "Fitting model...\n",
            "Fitted\n"
          ]
        }
      ],
      "source": [
        "import ast  # Substituir eval por ast.literal_eval para maior seguranÃ§a\n",
        "from utils.save_models_and_variables import load_model, load_variable\n",
        "try:\n",
        "    topic_model = load_model(f'{results_folder}/bertopic_{result_index}')\n",
        "    print(\"Previously calculated\" if topic_model else \"Will be calculated...\")\n",
        "\n",
        "    topics = load_variable(f'{results_folder}/topics_bertopic_{result_index}')\n",
        "    print(\"Topics previously calculated\" if topics else \"Topics will be calculated...\")\n",
        "\n",
        "    probs = load_variable(f'{results_folder}/probs_bertopic_{result_index}')\n",
        "    print(\"Probs previously calculated\" if probs is not None else \"Probs will be calculated...\")\n",
        "except:\n",
        "    topic_model = None\n",
        "    topics = None\n",
        "    probs = None\n",
        "\n",
        "if topic_model is None or probs is None or topics is None:\n",
        "    # sentences = unified_df[\"text\"]\n",
        "    \n",
        "    # Passo 2: Validar colunas no DataFrame\n",
        "    expected_columns = [\n",
        "        \"embedding_model\",\n",
        "        \"reduction_model\",\n",
        "        \"umap_params\",\n",
        "        \"clustering_model\",\n",
        "        \"representation_model\",\n",
        "        \"coherence\"  # Deve existir como mÃ©trica para identificar os melhores parÃ¢metros\n",
        "    ]\n",
        "\n",
        "    missing_columns = [col for col in expected_columns if col not in results_df.columns]\n",
        "    if missing_columns:\n",
        "        raise ValueError(f\"As colunas seguintes estÃ£o faltando no results_df: {missing_columns}\")\n",
        "\n",
        "    # Passo 3: Identificar os melhores parÃ¢metros\n",
        "    best_row = results_df.loc[results_df['coherence'].idxmax()]\n",
        "\n",
        "    # Garantir que umap_params seja convertido corretamente\n",
        "    try:\n",
        "        best_umap_params = ast.literal_eval(best_row['umap_params'])\n",
        "    except (ValueError, SyntaxError) as e:\n",
        "        raise ValueError(f\"Erro ao converter umap_params: {best_row['umap_params']}\") from e\n",
        "\n",
        "    # Extrair os melhores parÃ¢metros\n",
        "    best_params = {\n",
        "        \"embedding_model\": best_row['embedding_model'],\n",
        "        \"reduction_model\": best_row[\"reduction_model\"],\n",
        "        \"umap_params\": best_umap_params,\n",
        "        \"clustering_model\": best_row['clustering_model'],\n",
        "        \"representation_model\": best_row[\"representation_model\"],\n",
        "    }\n",
        "    best_coherence = best_row[\"coherence\"]\n",
        "\n",
        "    print(\"Melhores parÃ¢metros:\", best_params)\n",
        "    print(\"Melhor coerÃªncia:\", best_coherence)\n",
        "\n",
        "    # Continuar o restante do fluxo\n",
        "    print(\"Getting embedding model...\")\n",
        "    embedding_model = get_embedding_model(best_params[\"embedding_model\"])\n",
        "\n",
        "    print(\"Getting reduction model...\")\n",
        "    reduction_model = get_reduction_model(best_params[\"reduction_model\"], best_params[\"umap_params\"])\n",
        "\n",
        "    print(\"Getting clustering model...\")\n",
        "    clustering_model = get_clustering_model(best_params[\"clustering_model\"], 30)\n",
        "\n",
        "    print(\"Getting TFIDF model...\")\n",
        "    tfidf_vectorizer = TfidfVectorizer(stop_words='english', smooth_idf=True)\n",
        "\n",
        "    print(\"Getting representation model...\")\n",
        "    representation_model = get_representation_model(best_params[\"representation_model\"], None)\n",
        "    \n",
        "    print(\"Initializing model...\")\n",
        "    if topic_model is None:\n",
        "        topic_model = BERTopic(\n",
        "            language=\"portuguese\",\n",
        "            umap_model=reduction_model,\n",
        "            hdbscan_model=clustering_model,\n",
        "            vectorizer_model=tfidf_vectorizer,\n",
        "            representation_model=representation_model,\n",
        "            embedding_model=embedding_model,\n",
        "            min_topic_size=100,\n",
        "            nr_topics=5\n",
        "        )\n",
        "        \n",
        "    print(\"Fitting model...\")\n",
        "    topics, probs = topic_model.fit_transform(sentences)\n",
        "    print(\"Fitted\")\n",
        "    \n",
        "    try:\n",
        "        df[\"topic_id\"] = topics\n",
        "    except:\n",
        "        topic_mapping = dict(zip(sentences, topics))\n",
        "\n",
        "        # ðŸ”¹ 4ï¸âƒ£ Adicionar os tÃ³picos ao DataFrame\n",
        "        df['topic'] = df['text'].map(topic_mapping)\n",
        "else:\n",
        "    df = pd.read_csv(f\"{results_folder}/topic_data.csv\")\n",
        "    print(\"Topic data previously calculated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No outliers to reduce.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Certifique-se de que o modelo estÃ¡ treinado antes de reduzir os outliers\n",
        "    if not hasattr(topic_model, \"topic_sizes_\"):  # Verifica se jÃ¡ foi treinado\n",
        "        topic_model.fit(sentences)  # Treina o modelo com as frases\n",
        "\n",
        "    # Reduzindo outliers\n",
        "    new_topics = topic_model.reduce_outliers(sentences, topics, strategy='c-tf-idf', threshold=0.05)\n",
        "\n",
        "    # Criando o vetorizador TF-IDF (caso nÃ£o tenha sido definido antes)\n",
        "    vectorizer_model = TfidfVectorizer(stop_words='portuguese', smooth_idf=True)\n",
        "\n",
        "    # Atualizando o modelo com os novos tÃ³picos\n",
        "    topic_model.update_topics(sentences, topics=new_topics, vectorizer_model=vectorizer_model)\n",
        "\n",
        "    # Exibindo informaÃ§Ãµes sobre os tÃ³picos\n",
        "    print(topic_model.get_topic_info())\n",
        "    print(\"Outliers reduced\")\n",
        "except ValueError:\n",
        "    print(\"No outliers to reduce.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-15 12:01:33,883 - INFO - adding document #0 to Dictionary<0 unique tokens: []>\n",
            "2025-06-15 12:01:33,912 - INFO - built Dictionary<3981 unique tokens: ['###', '#conquistafeminina', '#mensagensdebomdia', '#psicologiamasculina', '#redpillfeminina']...> from 447 documents (total 52301 corpus positions)\n",
            "2025-06-15 12:01:33,912 - INFO - Dictionary lifecycle event {'msg': \"built Dictionary<3981 unique tokens: ['###', '#conquistafeminina', '#mensagensdebomdia', '#psicologiamasculina', '#redpillfeminina']...> from 447 documents (total 52301 corpus positions)\", 'datetime': '2025-06-15T12:01:33.912759', 'gensim': '4.3.3', 'python': '3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22631-SP0', 'event': 'created'}\n",
            "2025-06-15 12:01:33,914 - INFO - using ParallelWordOccurrenceAccumulator<processes=11, batch_size=64> to estimate probabilities from sliding windows\n",
            "2025-06-15 12:01:44,879 - INFO - 1 batches submitted to accumulate stats from 64 documents (651 virtual)\n",
            "2025-06-15 12:01:44,881 - INFO - 2 batches submitted to accumulate stats from 128 documents (1645 virtual)\n",
            "2025-06-15 12:01:44,883 - INFO - 3 batches submitted to accumulate stats from 192 documents (2157 virtual)\n",
            "2025-06-15 12:01:44,884 - INFO - 4 batches submitted to accumulate stats from 256 documents (2576 virtual)\n",
            "2025-06-15 12:01:44,885 - INFO - 5 batches submitted to accumulate stats from 320 documents (3553 virtual)\n",
            "2025-06-15 12:01:44,888 - INFO - 7 batches submitted to accumulate stats from 448 documents (3578 virtual)\n",
            "2025-06-15 12:01:45,062 - INFO - 11 accumulators retrieved from output queue\n",
            "2025-06-15 12:01:45,070 - INFO - accumulated word occurrence stats for 19259 virtual documents\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Esse modelo tem coerÃªncia de 0.8459217505426448\n"
          ]
        }
      ],
      "source": [
        "coherence_score = calculate_coherence(topic_model, sentences)\n",
        "\n",
        "print(f\"Esse modelo tem coerÃªncia de {coherence_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'evitar_feito_antiotÃ¡rio_ser_redpillbrasil',\n",
              " 1: 'memes_vindo_humor_canal_nÃ£o',\n",
              " 2: 'capÃ­tulo_como_homem_ele_emocional',\n",
              " 3: 'http_redcast_master_junior_instagram',\n",
              " 4: 'http_conselho_projetoconselhosubstackcom_comercial_recomendo',\n",
              " -1: 'outlier'}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# DicionÃ¡rio para armazenar os nomes dos tÃ³picos\n",
        "topic_names_dict = {}\n",
        "\n",
        "# Obter informaÃ§Ãµes dos tÃ³picos\n",
        "topics = topic_model.get_topic_info()\n",
        "\n",
        "# Gerar tÃ­tulos para os tÃ³picos\n",
        "for topic_id in topics['Topic']:\n",
        "    top_words = [word for word, _ in topic_model.get_topic(topic_id)[:5]]\n",
        "    topic_name = \"_\".join(top_words)\n",
        "    topic_names_dict[topic_id] = topic_name\n",
        "    \n",
        "topic_names_dict[-1] = 'outlier'\n",
        "\n",
        "# Exibir o dicionÃ¡rio resultante\n",
        "topic_names_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6 topicos gerados\n"
          ]
        }
      ],
      "source": [
        "print(f\"{len(topic_names_dict)} topicos gerados\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "447 antes do filtro\n",
            "447 depois do filtro\n"
          ]
        }
      ],
      "source": [
        "print(f\"{len(df)} antes do filtro\")\n",
        "df = df.drop_duplicates(subset=[ \"video_id\"])\n",
        "df = df.dropna(subset=[\"video_id\"])\n",
        "print(f\"{len(df)} depois do filtro\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸ”¹ 4ï¸âƒ£ ComparaÃ§Ã£o dentro de cada caso   \n",
        "def print_topic(case):\n",
        "    case_df = df[df[\"case\"] == case]\n",
        "    \n",
        "    print(f\"\\nðŸ”¹ ComparaÃ§Ã£o de tÃ³picos para o caso: {case}\")\n",
        "    \n",
        "    # Verificar quando o mesmo autor tem um tÃ³pico diferente para vÃ­deo e notÃ­cia\n",
        "    differing_topics = case_df[case_df[\"news_topic\"] != case_df[\"video_topic\"]]\n",
        "    \n",
        "    print(f\"NÃºmero de diferenÃ§as entre tÃ³picos no caso {case}: {len(differing_topics)}\")\n",
        "\n",
        "    # Se quiser ver exemplos especÃ­ficos de diferenÃ§as:\n",
        "    return differing_topics[['news_author', 'video_author', 'news_topic', 'video_topic', 'news_title', 'video_title', 'news_text', 'video_text']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ExportaÃ§Ã£o de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved model: results_2025_06_10/bertopic.pkl\n",
            "Saved variable: results_2025_06_10/topics_bertopic.pkl\n",
            "Saved variable: results_2025_06_10/probs_bertopic.pkl\n",
            "Saved variable: results_2025_06_10/topics_dict.pkl\n"
          ]
        }
      ],
      "source": [
        "from utils.save_models_and_variables import save_model, save_variable\n",
        "\n",
        "save_model(topic_model, f'{results_folder}/bertopic')\n",
        "save_variable(topics, f'{results_folder}/topics_bertopic')\n",
        "save_variable(probs, f'{results_folder}/probs_bertopic')\n",
        "save_variable(topic_names_dict, f'{results_folder}/topics_dict')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "fWYMqE0xYpOz"
      },
      "outputs": [],
      "source": [
        "df.to_csv(f'{results_folder}/topic_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "447"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
